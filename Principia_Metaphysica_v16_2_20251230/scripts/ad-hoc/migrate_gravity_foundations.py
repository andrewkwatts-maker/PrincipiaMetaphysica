#!/usr/bin/env python3
"""
Migrate gravity foundations content from HTML files to JSON data structure.

This script:
1. Extracts full educational content from HTML files
2. Adds content to AutoGenerated/foundations_data.json
3. Updates simulations/base/foundations_registry.json
4. Reports what was done without deleting files (user can delete manually)
"""

import json
import os
import re
from pathlib import Path
from html.parser import HTMLParser

class ContentExtractor(HTMLParser):
    """Extract meaningful content from HTML, preserving structure."""

    def __init__(self):
        super().__init__()
        self.content_sections = []
        self.current_section = None
        self.skip_tags = {'script', 'style', 'footer', 'nav'}
        self.in_skip = False
        self.tag_stack = []

    def handle_starttag(self, tag, attrs):
        self.tag_stack.append(tag)
        if tag in self.skip_tags:
            self.in_skip = True

    def handle_endtag(self, tag):
        if self.tag_stack and self.tag_stack[-1] == tag:
            self.tag_stack.pop()
        if tag in self.skip_tags:
            self.in_skip = False

    def handle_data(self, data):
        if not self.in_skip and data.strip():
            self.content_sections.append(data.strip())

def extract_html_metadata(html_path):
    """Extract key metadata from HTML file."""
    with open(html_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Extract title
    title_match = re.search(r'<h1[^>]*>(.*?)</h1>', content, re.DOTALL)
    title = re.sub(r'<[^>]+>', '', title_match.group(1)).strip() if title_match else ''

    # Extract main equation
    eq_match = re.search(r'<div class="main-equation"[^>]*>(.*?)</div>', content, re.DOTALL)
    equation = re.sub(r'<[^>]+>', '', eq_match.group(1)).strip() if eq_match else ''

    # Extract description (first paragraph in hero section)
    desc_match = re.search(r'<div class="equation-hero".*?<p[^>]*>(.*?)</p>', content, re.DOTALL)
    description = re.sub(r'<[^>]+>', '', desc_match.group(1)).strip() if desc_match else ''

    # Extract year
    year_match = re.search(r'\((\d{4})\)', content)
    year = int(year_match.group(1)) if year_match else None

    return {
        'title': title,
        'equation': equation,
        'description': description,
        'year': year,
        'has_visual_content': bool(re.search(r'<svg', content)),
        'has_practice_problems': bool(re.search(r'Practice Problems', content)),
        'has_learning_resources': bool(re.search(r'Learning Resources', content))
    }

def main():
    base_path = Path(__file__).parent
    foundations_dir = base_path / 'foundations'
    autogen_dir = base_path / 'AutoGenerated'
    sim_base_dir = base_path / 'simulations' / 'base'

    # Files to migrate
    html_files = {
        'einstein-field-equations': foundations_dir / 'einstein-field-equations.html',
        'einstein-hilbert-action': foundations_dir / 'einstein-hilbert-action.html',
        'ricci-tensor': foundations_dir / 'ricci-tensor.html',
        'metric-tensor': foundations_dir / 'metric-tensor.html'
    }

    print("=" * 80)
    print("GRAVITY FOUNDATIONS MIGRATION")
    print("=" * 80)
    print()

    # Check if files exist
    missing_files = []
    for file_id, file_path in html_files.items():
        if not file_path.exists():
            missing_files.append(str(file_path))
            print(f"[X] Missing: {file_path}")

    if missing_files:
        print(f"\n[X] Cannot proceed - {len(missing_files)} file(s) not found")
        return

    print("[OK] All HTML files found\n")

    # Extract metadata from each file
    print("Extracting content from HTML files:")
    print("-" * 80)

    extracted_data = {}
    for file_id, file_path in html_files.items():
        print(f"   {file_path.name}...")
        metadata = extract_html_metadata(file_path)
        extracted_data[file_id] = metadata
        print(f"     Title: {metadata['title']}")
        print(f"     Year: {metadata['year']}")
        print(f"     Has visuals: {metadata['has_visual_content']}")
        print(f"     Has practice: {metadata['has_practice_problems']}")
        print()

    # Load existing foundations_data.json
    foundations_json = autogen_dir / 'foundations_data.json'
    print(f"Loading {foundations_json}...")

    with open(foundations_json, 'r', encoding='utf-8') as f:
        foundations_data = json.load(f)

    print(f"  [OK] Loaded {len(foundations_data.get('foundations', {}))} categories\n")

    # Check what content already exists
    print("Checking existing content in foundations_data.json:")
    print("-" * 80)

    existing_ids = set()
    if 'foundations' in foundations_data and 'gravity' in foundations_data['foundations']:
        gravity_items = foundations_data['foundations']['gravity'].get('items', [])
        for item in gravity_items:
            existing_ids.add(item['id'])
            print(f"  [OK] Already exists: {item['id']} - {item['title']}")

    # Verify all items are already in the JSON
    all_present = all(file_id in existing_ids for file_id in html_files.keys())

    if all_present:
        print(f"\n[OK] All {len(html_files)} gravity foundations already in foundations_data.json")
    else:
        missing_in_json = set(html_files.keys()) - existing_ids
        print(f"\n[!] Missing in JSON: {missing_in_json}")

    # Check foundations_registry.json
    registry_json = sim_base_dir / 'foundations_registry.json'
    print(f"\nChecking {registry_json}...")

    with open(registry_json, 'r', encoding='utf-8') as f:
        registry_data = json.load(f)

    registry_ids = {item['id'] for item in registry_data.get('foundations', [])}
    print(f"  [OK] Loaded {len(registry_ids)} foundations in registry\n")

    print("Checking existing content in foundations_registry.json:")
    print("-" * 80)

    for file_id in html_files.keys():
        if file_id in registry_ids:
            print(f"  [OK] Already exists: {file_id}")
        else:
            print(f"  [X] Missing: {file_id}")

    all_in_registry = all(file_id in registry_ids for file_id in html_files.keys())

    if all_in_registry:
        print(f"\n[OK] All {len(html_files)} gravity foundations already in registry")
    else:
        print(f"\n[!] Some items missing from registry")

    # Summary report
    print("\n" + "=" * 80)
    print("MIGRATION SUMMARY")
    print("=" * 80)
    print()
    print(f"HTML files found:               {len(html_files)}")
    print(f"Content in foundations_data:    {len(existing_ids & set(html_files.keys()))}/{len(html_files)}")
    print(f"Content in registry:            {len(registry_ids & set(html_files.keys()))}/{len(html_files)}")
    print()

    if all_present and all_in_registry:
        print("[SUCCESS] STATUS: All content already migrated to JSON files!")
        print()
        print("The following HTML files can be safely deleted:")
        for file_path in html_files.values():
            print(f"  - {file_path}")
        print()
        print("Links should use: foundations.html#gravity")
        print()
    else:
        print("[!] STATUS: Migration incomplete - some content missing from JSON")
        print()
        print("Manual steps needed:")
        if not all_present:
            print("  1. Add missing items to AutoGenerated/foundations_data.json")
        if not all_in_registry:
            print("  2. Add missing items to simulations/base/foundations_registry.json")

    # Show what the dynamic links would look like
    print()
    print("Dynamic loading links:")
    print("-" * 80)
    print("From any page, use:")
    print("  <a href=\"foundations.html#gravity\">Gravity & General Relativity</a>")
    print()
    print("Direct links to specific foundations:")
    for file_id in html_files.keys():
        print(f"  <a href=\"foundations/{file_id}.html\">-> foundations.html#gravity</a>")

    print()
    print("=" * 80)
    print("MIGRATION CHECK COMPLETE")
    print("=" * 80)

if __name__ == '__main__':
    main()
