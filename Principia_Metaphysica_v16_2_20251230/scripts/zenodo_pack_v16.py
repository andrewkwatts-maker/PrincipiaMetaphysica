#!/usr/bin/env python3
"""
Zenodo Package Builder for Principia Metaphysica v16.2
======================================================

This script creates a self-contained, offline-capable archive suitable for
Zenodo submission. It follows a "Build, Strip, and Seal" workflow:

1. BUILD: Copy necessary files to a clean directory
2. STRIP: Remove/neutralize authentication and secrets
3. SEAL: Generate checksums and create ZIP archive

The resulting package can be unzipped and run on any machine without
network access or authentication credentials.

Usage:
    python scripts/zenodo_pack_v16.py [--test] [--no-zip]

Options:
    --test      Run clean-room verification after building
    --no-zip    Build directory only, don't create ZIP

Copyright (c) 2025-2026 Andrew Keith Watts. All rights reserved.

Dedicated To:
    My Wife: Elizabeth May Watts
    Our Messiah: Jesus Of Nazareth
"""

import os
import sys
import shutil
import zipfile
import hashlib
import json
import datetime
import argparse
from pathlib import Path
from typing import Set, Dict, List, Optional

# ============================================================================
# CONFIGURATION
# ============================================================================

VERSION = "16.2"
RELEASE_DATE = datetime.datetime.now().strftime("%Y%m%d")

# Source and build directories
SOURCE_DIR = Path(__file__).parent.parent  # Project root
BUILD_DIR = SOURCE_DIR / f"Principia_Metaphysica_v{VERSION.replace('.', '_')}_{RELEASE_DATE}"
ZIP_NAME = f"Principia_Metaphysica_v{VERSION.replace('.', '_')}_{RELEASE_DATE}.zip"

# Directories to exclude entirely
EXCLUDE_DIRS: Set[str] = {
    '.git',
    '.github',
    '__pycache__',
    '.pytest_cache',
    'node_modules',
    '.venv',
    'venv',
    '.env',
    'private',
    '.claude',
    'zenodo_submission',  # Temporary submission folder
    'firebase-backup',
}

# Files to exclude
EXCLUDE_FILES: Set[str] = {
    '.gitignore',
    '.DS_Store',
    'Thumbs.db',
    '.env',
    '.env.local',
    'serviceAccountKey.json',
    'package-lock.json',
    'nul',
}

# Files to strip/neutralize (secrets, auth guards)
STRIP_FILES: Dict[str, str] = {
    'secrets_config.py': '''#!/usr/bin/env python3
"""
SECRETS CONFIGURATION - ZENODO RELEASE (STRIPPED)
=================================================

This file has been stripped of actual API keys for Zenodo release.
For local development, replace the placeholder values with your actual API keys.

Get your Wolfram Alpha App ID at: https://developer.wolframalpha.com/
"""

# Wolfram Alpha API - Replace with your own App ID for local use
WOLFRAM_APP_ID = "YOUR_APP_ID_HERE"

# API Configuration (unchanged)
WOLFRAM_API_TIMEOUT = 30  # seconds
WOLFRAM_MAX_RETRIES = 3

# Validation settings (unchanged)
VALIDATION_CACHE_DIR = "AutoGenerated/validations/"
PROOF_MANIFEST_PATH = "AutoGenerated/proof_manifest.json"
''',
    'auth_guard.py': '''#!/usr/bin/env python3
"""
AUTH GUARD - ZENODO RELEASE (BYPASSED)
======================================

This module has been neutralized for offline Zenodo release.
All authentication checks return True to allow offline verification.
"""

def check_access():
    """Always returns True for offline access."""
    return True

def login_required(func):
    """Decorator that does nothing (bypasses login requirement)."""
    return func

def verify_token(token):
    """Always returns True for offline verification."""
    return True

class AuthGuard:
    """Neutralized auth guard for offline use."""

    def __init__(self):
        self.authenticated = True

    def check(self):
        return True

    def require_auth(self, func):
        return func
''',
}

# Patterns for files to exclude (glob-style)
EXCLUDE_PATTERNS: List[str] = [
    '*_secrets.py',
    '*_secret.py',
    '*.pyc',
    '*.pyo',
    '*.pyd',
    '*.so',
    '*.egg-info',
    '*.egg',
    '*.log',
    '*.tmp',
    '*.temp',
    '*.bak',
    '*~',
    '*.swp',
    '*.swo',
]

# Directories to include (if not in EXCLUDE_DIRS)
INCLUDE_DIRS: List[str] = [
    'simulations',
    'AutoGenerated',
    'js',
    'css',
    'data',
    'docs',
    'images',
    'diagrams',
    'Pages',
    'foundations',
    'formal_proofs',
    'components',
    'examples',
    'tests',
    'scripts',
    'utils',
]

# Key files to include from root
INCLUDE_ROOT_FILES: List[str] = [
    'config.py',
    'README.md',
    'LICENSE',
    'CITATION.cff',
    'ARCHITECTURE.md',
    'PROVENANCE.md',
    'PEER_REVIEW_DEFENSE.md',
    'index.html',
    'principia-metaphysica-paper.html',
    'IMPLEMENTATION_PLAN_v16_2.md',
    'serve.py',
    'start_server.bat',
]

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def should_exclude_dir(dirname: str) -> bool:
    """Check if a directory should be excluded."""
    return dirname in EXCLUDE_DIRS or dirname.startswith('.')

def should_exclude_file(filename: str) -> bool:
    """Check if a file should be excluded."""
    if filename in EXCLUDE_FILES:
        return True
    if filename.startswith('.'):
        return True
    for pattern in EXCLUDE_PATTERNS:
        if pattern.startswith('*') and filename.endswith(pattern[1:]):
            return True
        if pattern.endswith('*') and filename.startswith(pattern[:-1]):
            return True
    return False

def compute_sha256(file_path: Path) -> str:
    """Compute SHA-256 hash of a file."""
    sha256 = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha256.update(chunk)
    return sha256.hexdigest()

def compute_sha512(file_path: Path) -> str:
    """Compute SHA-512 hash of a file."""
    sha512 = hashlib.sha512()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha512.update(chunk)
    return sha512.hexdigest()

# ============================================================================
# MAIN BUILD FUNCTIONS
# ============================================================================

def clean_build_dir():
    """Remove existing build directory if it exists."""
    if BUILD_DIR.exists():
        print(f"  Removing existing build directory: {BUILD_DIR.name}")
        shutil.rmtree(BUILD_DIR)
    BUILD_DIR.mkdir(parents=True)
    print(f"  Created clean build directory: {BUILD_DIR.name}")

def copy_directory(src: Path, dst: Path, strip_files: Dict[str, str]):
    """
    Recursively copy a directory, excluding and stripping as needed.

    Args:
        src: Source directory
        dst: Destination directory
        strip_files: Dict mapping filename to replacement content
    """
    if not src.exists():
        return

    dst.mkdir(parents=True, exist_ok=True)

    for item in src.iterdir():
        if item.is_dir():
            if not should_exclude_dir(item.name):
                copy_directory(item, dst / item.name, strip_files)
        else:
            if should_exclude_file(item.name):
                continue

            dest_file = dst / item.name

            # Check if this file should be stripped
            if item.name in strip_files:
                print(f"    [STRIPPED] {item.relative_to(SOURCE_DIR)}")
                with open(dest_file, 'w', encoding='utf-8') as f:
                    f.write(strip_files[item.name])
            else:
                shutil.copy2(item, dest_file)

def copy_root_files():
    """Copy important root-level files."""
    print("\n  Copying root files...")
    for filename in INCLUDE_ROOT_FILES:
        src = SOURCE_DIR / filename
        if src.exists():
            shutil.copy2(src, BUILD_DIR / filename)
            print(f"    Copied: {filename}")
        else:
            print(f"    [MISSING] {filename}")

def copy_include_directories():
    """Copy all included directories."""
    print("\n  Copying directories...")
    for dirname in INCLUDE_DIRS:
        src = SOURCE_DIR / dirname
        if src.exists() and src.is_dir():
            print(f"    Copying: {dirname}/")
            copy_directory(src, BUILD_DIR / dirname, STRIP_FILES)
        else:
            print(f"    [SKIP] {dirname}/ (not found)")

def create_offline_config():
    """Create offline configuration files for the website."""
    print("\n  Creating offline configuration...")

    # Create offline mode config for JavaScript
    offline_config_js = BUILD_DIR / "js" / "offline-config.js"
    offline_config_js.parent.mkdir(parents=True, exist_ok=True)

    with open(offline_config_js, 'w', encoding='utf-8') as f:
        f.write('''// Principia Metaphysica - Offline Mode Configuration
// Auto-generated for Zenodo release

window.PM_CONFIG = {
    mode: 'offline',
    dataSource: 'local',
    version: '%s',
    releaseDate: '%s',

    // Local data paths (relative to index.html)
    paths: {
        formulas: './AutoGenerated/formulas.json',
        parameters: './AutoGenerated/parameters.json',
        simulations: './AutoGenerated/simulations.json',
        sections: './AutoGenerated/sections.json',
        metadata: './AutoGenerated/metadata.json',
        theoryOutput: './AutoGenerated/theory_output.json',
    },

    // Disable features that require network
    features: {
        apiCalls: false,
        cloudSync: false,
        authentication: false,
        analytics: false,
    }
};

// Signal offline mode to other scripts
window.PM_OFFLINE = true;
console.log('[PM] Running in offline mode (Zenodo release)');
''' % (VERSION, RELEASE_DATE))

    print(f"    Created: js/offline-config.js")

def create_package_manifest():
    """Create a manifest of all files in the package."""
    print("\n  Creating package manifest...")

    manifest = {
        "package": "Principia Metaphysica",
        "version": VERSION,
        "release_date": RELEASE_DATE,
        "build_timestamp": datetime.datetime.now().isoformat(),
        "description": "Complete computational implementation of Principia Metaphysica theory",
        "author": "Andrew Keith Watts",
        "license": "MIT (code), See LICENSE for theory content",
        "files": [],
        "checksums": {}
    }

    file_count = 0
    total_size = 0

    for root, dirs, files in os.walk(BUILD_DIR):
        # Filter out excluded directories
        dirs[:] = [d for d in dirs if not should_exclude_dir(d)]

        for filename in files:
            filepath = Path(root) / filename
            rel_path = filepath.relative_to(BUILD_DIR)
            file_size = filepath.stat().st_size

            manifest["files"].append({
                "path": str(rel_path),
                "size": file_size,
                "sha256": compute_sha256(filepath)[:16] + "..."  # Truncated for readability
            })

            file_count += 1
            total_size += file_size

    manifest["summary"] = {
        "total_files": file_count,
        "total_size_bytes": total_size,
        "total_size_mb": round(total_size / (1024 * 1024), 2)
    }

    # Write manifest
    manifest_path = BUILD_DIR / "MANIFEST.json"
    with open(manifest_path, 'w', encoding='utf-8') as f:
        json.dump(manifest, f, indent=2)

    print(f"    Files: {file_count}")
    print(f"    Size: {manifest['summary']['total_size_mb']} MB")
    print(f"    Created: MANIFEST.json")

    return manifest

def create_verification_script():
    """Create a standalone verification script."""
    print("\n  Creating verification script...")

    verify_script = BUILD_DIR / "verify_package.py"

    with open(verify_script, 'w', encoding='utf-8') as f:
        f.write('''#!/usr/bin/env python3
"""
Principia Metaphysica Package Verification Script
=================================================

Run this script to verify the integrity and functionality of the package.

Usage:
    python verify_package.py [--full]

Options:
    --full    Run full simulation tests (takes longer)
"""

import os
import sys
import json
import hashlib
from pathlib import Path

def main():
    print("=" * 60)
    print(" Principia Metaphysica Package Verification")
    print("=" * 60)

    package_dir = Path(__file__).parent
    errors = []
    warnings = []

    # 1. Check manifest exists
    print("\\n[1/5] Checking manifest...")
    manifest_path = package_dir / "MANIFEST.json"
    if not manifest_path.exists():
        errors.append("MANIFEST.json not found")
    else:
        with open(manifest_path) as f:
            manifest = json.load(f)
        print(f"      Version: {manifest['version']}")
        print(f"      Files: {manifest['summary']['total_files']}")

    # 2. Check critical files exist
    print("\\n[2/5] Checking critical files...")
    critical_files = [
        "config.py",
        "README.md",
        "LICENSE",
        "AutoGenerated/formulas.json",
        "AutoGenerated/parameters.json",
        "simulations/base/__init__.py",
    ]
    for cf in critical_files:
        if not (package_dir / cf).exists():
            errors.append(f"Missing: {cf}")
        else:
            print(f"      OK: {cf}")

    # 3. Check Python imports
    print("\\n[3/5] Checking Python imports...")
    sys.path.insert(0, str(package_dir))
    try:
        import config
        print("      OK: config.py imports")
    except Exception as e:
        errors.append(f"config.py import failed: {e}")

    try:
        from simulations.base import PMRegistry
        print("      OK: simulations.base imports")
    except Exception as e:
        errors.append(f"simulations.base import failed: {e}")

    # 4. Check JSON data files
    print("\\n[4/5] Checking JSON data files...")
    json_files = [
        "AutoGenerated/formulas.json",
        "AutoGenerated/parameters.json",
        "AutoGenerated/simulations.json",
    ]
    for jf in json_files:
        jf_path = package_dir / jf
        if jf_path.exists():
            try:
                with open(jf_path, encoding='utf-8') as f:
                    data = json.load(f)
                print(f"      OK: {jf} ({len(data) if isinstance(data, list) else 'valid'} entries)")
            except json.JSONDecodeError as e:
                errors.append(f"Invalid JSON in {jf}: {e}")
            except UnicodeDecodeError as e:
                warnings.append(f"Encoding issue in {jf}: {e}")

    # 5. Quick simulation test
    print("\\n[5/5] Quick simulation test...")
    try:
        from simulations.base import PMRegistry
        from simulations.base.established import EstablishedPhysics

        registry = PMRegistry()
        EstablishedPhysics.load_into_registry(registry)

        alpha = registry.get_param("constants.alpha_em")
        print(f"      OK: alpha_em = {alpha:.6e}")
    except Exception as e:
        warnings.append(f"Simulation test warning: {e}")

    # Summary
    print("\\n" + "=" * 60)
    if errors:
        print(f" FAILED - {len(errors)} error(s)")
        for e in errors:
            print(f"   ERROR: {e}")
        sys.exit(1)
    elif warnings:
        print(f" PASSED with {len(warnings)} warning(s)")
        for w in warnings:
            print(f"   WARN: {w}")
    else:
        print(" PASSED - All checks successful")
    print("=" * 60)

if __name__ == "__main__":
    main()
''')

    print(f"    Created: verify_package.py")

def create_zip_archive():
    """Create the final ZIP archive with checksum."""
    print("\n  Creating ZIP archive...")

    zip_path = SOURCE_DIR / ZIP_NAME

    # Create ZIP
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        for root, dirs, files in os.walk(BUILD_DIR):
            dirs[:] = [d for d in dirs if not should_exclude_dir(d)]

            for filename in files:
                filepath = Path(root) / filename
                arcname = filepath.relative_to(BUILD_DIR.parent)
                zf.write(filepath, arcname)

    # Compute checksums
    zip_size = zip_path.stat().st_size
    sha256 = compute_sha256(zip_path)
    sha512 = compute_sha512(zip_path)

    print(f"    Archive: {ZIP_NAME}")
    print(f"    Size: {zip_size / (1024*1024):.2f} MB")
    print(f"    SHA-256: {sha256}")

    # Write checksum file
    checksum_path = SOURCE_DIR / f"{ZIP_NAME}.sha256"
    with open(checksum_path, 'w') as f:
        f.write(f"{sha256}  {ZIP_NAME}\n")
    print(f"    Created: {ZIP_NAME}.sha256")

    return zip_path, sha256, sha512

def run_clean_room_test():
    """Run verification in the built package directory."""
    print("\n  Running clean room verification...")

    # Change to build directory and run verification
    import subprocess

    result = subprocess.run(
        [sys.executable, "verify_package.py"],
        cwd=BUILD_DIR,
        capture_output=True,
        text=True
    )

    print(result.stdout)
    if result.returncode != 0:
        print(f"  [WARNING] Verification returned non-zero: {result.returncode}")
        if result.stderr:
            print(result.stderr)
        return False
    return True

# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description="Build Zenodo package for Principia Metaphysica")
    parser.add_argument("--test", action="store_true", help="Run clean-room verification after building")
    parser.add_argument("--no-zip", action="store_true", help="Build directory only, don't create ZIP")
    args = parser.parse_args()

    print("=" * 70)
    print(f" PRINCIPIA METAPHYSICA - ZENODO PACKAGE BUILDER v{VERSION}")
    print("=" * 70)
    print(f"\nSource: {SOURCE_DIR}")
    print(f"Build:  {BUILD_DIR.name}")
    print(f"Output: {ZIP_NAME}")

    # Step 1: Clean and prepare
    print("\n[1/6] Preparing build directory...")
    clean_build_dir()

    # Step 2: Copy root files
    print("\n[2/6] Copying root files...")
    copy_root_files()

    # Step 3: Copy directories
    print("\n[3/6] Copying directories...")
    copy_include_directories()

    # Step 4: Create offline config
    print("\n[4/6] Creating offline configuration...")
    create_offline_config()
    create_verification_script()

    # Step 5: Create manifest
    print("\n[5/6] Creating package manifest...")
    manifest = create_package_manifest()

    # Step 6: Create ZIP
    if not args.no_zip:
        print("\n[6/6] Creating ZIP archive...")
        zip_path, sha256, sha512 = create_zip_archive()
    else:
        print("\n[6/6] Skipping ZIP creation (--no-zip)")

    # Optional: Run tests
    if args.test:
        print("\n" + "=" * 70)
        print(" CLEAN ROOM VERIFICATION")
        print("=" * 70)
        success = run_clean_room_test()
        if not success:
            print("\n[!] Some tests failed - check output above")

    # Summary
    print("\n" + "=" * 70)
    print(" BUILD COMPLETE")
    print("=" * 70)
    print(f"\nBuild directory: {BUILD_DIR}")
    if not args.no_zip:
        print(f"ZIP archive: {SOURCE_DIR / ZIP_NAME}")
        print(f"Checksum: {SOURCE_DIR / f'{ZIP_NAME}.sha256'}")
    print(f"\nTotal files: {manifest['summary']['total_files']}")
    print(f"Total size: {manifest['summary']['total_size_mb']} MB")
    print("\n[!] Remember to test on a clean machine before uploading to Zenodo!")
    print("=" * 70)

if __name__ == "__main__":
    main()
