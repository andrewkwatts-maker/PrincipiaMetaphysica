#!/usr/bin/env python3
"""
Generate comprehensive simulation_index.json for dynamic loading.
Scans entire simulations/ folder and extracts metadata from each file.
"""

import os
import json
from pathlib import Path
from datetime import datetime
import re

# Base paths
BASE_DIR = Path(r"h:\Github\PrincipiaMetaphysica")
SIMULATIONS_DIR = BASE_DIR / "simulations"
OUTPUT_DIR = BASE_DIR / "AutoGenerated"
OUTPUT_FILE = OUTPUT_DIR / "simulation_index.json"

# GitHub base URL for raw file access
GITHUB_RAW_BASE = "https://raw.githubusercontent.com/nshkrdotcom/PrincipiaMetaphysica/main/simulations"


def extract_docstring(filepath):
    """Extract the first docstring from a Python file."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            # Match both single and triple quotes
            match = re.search(r'"""(.*?)"""', content, re.DOTALL)
            if match:
                doc = match.group(1).strip()
                # Take first line only
                return doc.split('\n')[0].strip()
            match = re.search(r"'''(.*?)'''", content, re.DOTALL)
            if match:
                doc = match.group(1).strip()
                return doc.split('\n')[0].strip()
    except Exception as e:
        pass
    return ""


def extract_version(filename):
    """Extract version from filename like 'something_v16_0.py'."""
    match = re.search(r'v(\d+)_(\d+)', filename)
    if match:
        return f"{match.group(1)}.{match.group(2)}"
    match = re.search(r'v(\d+)', filename)
    if match:
        return f"{match.group(1)}.0"
    return "1.0"


def get_file_stats(filepath):
    """Get line count and file size."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = len(f.readlines())
        size_kb = os.path.getsize(filepath) / 1024
        return lines, round(size_kb, 2)
    except Exception:
        return 0, 0


def categorize_file(rel_path):
    """Determine domain/category from file path."""
    parts = Path(rel_path).parts

    if 'v16' in parts:
        idx = parts.index('v16')
        if idx + 1 < len(parts):
            return f"v16/{parts[idx + 1]}"
        return "v16/core"

    if 'base' in parts:
        return "base"

    if 'data' in parts:
        return "data"

    if 'derivations' in parts:
        return "derivations"

    if 'Constants' in parts:
        return "constants"

    if 'validation' in parts:
        return "validation"

    if 'ip' in parts:
        return "ip"

    if 'tests' in parts:
        return "tests"

    if 'reports' in parts:
        return "reports"

    return "root"


def get_domain_name(domain_key):
    """Get human-readable name for domain."""
    domain_names = {
        "v16/gauge": "Gauge Unification",
        "v16/cosmology": "Cosmological Models",
        "v16/fermion": "Fermion Sector",
        "v16/neutrino": "Neutrino Physics",
        "v16/geometric": "Geometric Foundations",
        "v16/higgs": "Higgs Mechanism",
        "v16/proton": "Proton Decay",
        "v16/thermal": "Thermal Physics",
        "v16/pneuma": "Consciousness & Pneuma",
        "v16/discussion": "Discussion & Analysis",
        "v16/predictions": "Predictions & Tests",
        "v16/introduction": "Introduction",
        "v16/appendices": "Appendices",
        "v16/statistics": "Statistical Analysis",
        "v16/validation": "Validation Suite",
        "v16/core": "Core V16 Framework",
        "base": "Base Infrastructure",
        "data": "Data Loaders",
        "derivations": "Mathematical Derivations",
        "constants": "Constants & Utilities",
        "validation": "Validation Tools",
        "ip": "Intellectual Property",
        "tests": "Test Suite",
        "reports": "Reports & Analysis",
        "root": "Root Simulations"
    }
    return domain_names.get(domain_key, domain_key.title())


def build_file_tree(files):
    """Build hierarchical tree structure from flat file list."""
    tree = {}

    for file_info in files:
        parts = Path(file_info['path']).parts
        # Skip first part which is 'simulations'
        parts = parts[1:]

        current = tree
        for i, part in enumerate(parts):
            if part not in current:
                if i == len(parts) - 1:
                    # Leaf node (file)
                    current[part] = file_info
                else:
                    # Directory node
                    current[part] = {}
            current = current[part] if i < len(parts) - 1 else current

    return tree


def scan_simulations():
    """Scan all Python files in simulations directory."""
    files = []
    domains = {}

    # Find all Python files
    for py_file in SIMULATIONS_DIR.rglob("*.py"):
        # Skip __pycache__ and similar
        if '__pycache__' in str(py_file):
            continue

        # Get relative path from simulations/
        try:
            rel_path = py_file.relative_to(SIMULATIONS_DIR)
        except ValueError:
            continue

        # Create GitHub raw URL
        github_url = f"{GITHUB_RAW_BASE}/{rel_path.as_posix()}"

        # Extract metadata
        description = extract_docstring(py_file)
        version = extract_version(py_file.name)
        lines, size_kb = get_file_stats(py_file)
        domain = categorize_file(rel_path)

        file_info = {
            "name": py_file.name,
            "path": f"simulations/{rel_path.as_posix()}",
            "github_url": github_url,
            "description": description or f"Simulation module: {py_file.stem}",
            "version": version,
            "lines": lines,
            "size_kb": size_kb
        }

        files.append(file_info)

        # Add to domain
        if domain not in domains:
            domains[domain] = {
                "name": get_domain_name(domain),
                "files": []
            }
        domains[domain]["files"].append(file_info)

    # Sort files in each domain
    for domain in domains.values():
        domain["files"].sort(key=lambda x: x["name"])

    return files, domains


def main():
    """Generate simulation_index.json."""
    print(f"Scanning {SIMULATIONS_DIR}...")

    files, domains = scan_simulations()

    print(f"Found {len(files)} Python files across {len(domains)} domains")

    # Build file tree
    file_tree = build_file_tree(files)

    # Create index structure
    index = {
        "generated": datetime.now().strftime("%Y-%m-%d"),
        "total_files": len(files),
        "domains": domains,
        "file_tree": file_tree,
        "all_files": sorted(files, key=lambda x: x["path"])
    }

    # Ensure output directory exists
    OUTPUT_DIR.mkdir(exist_ok=True)

    # Write JSON
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(index, f, indent=2, ensure_ascii=False)

    print(f"\nGenerated: {OUTPUT_FILE}")
    print(f"Total files: {len(files)}")
    print(f"Domains: {len(domains)}")

    # Print domain summary
    print("\nDomain Summary:")
    for domain_key in sorted(domains.keys()):
        domain = domains[domain_key]
        print(f"  {domain['name']}: {len(domain['files'])} files")


if __name__ == "__main__":
    main()
