#!/usr/bin/env python3
"""
PRINCIPIA METAPHYSICA - Simulations Index Generator
====================================================

Auto-generates simulations-index.json by scanning simulations directory.

For each Python script, extracts:
- Filename and path
- Version number (e.g., v15_0 -> 15.0)
- Docstring (first line as description)
- Status from docstring if available (CORE, PREDICTION, VALIDATED, etc.)
- Category from directory structure

Outputs to: AutoGenerated/simulations-index.json

Copyright (c) 2025 Andrew Keith Watts. All rights reserved.
"""

import os
import re
import json
import sys
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional

# Root directory
ROOT_DIR = Path(__file__).parent.parent.parent
SIMULATIONS_DIR = ROOT_DIR / "simulations"
OUTPUT_FILE = ROOT_DIR / "AutoGenerated" / "simulations-index.json"

# Ensure AutoGenerated directory exists
OUTPUT_FILE.parent.mkdir(exist_ok=True)

# Version from theory_output.json if available
VERSION = "16.2"
try:
    theory_output_path = ROOT_DIR / "AutoGenerated" / "theory_output.json"
    if theory_output_path.exists():
        with open(theory_output_path, 'r', encoding='utf-8') as f:
            theory_data = json.load(f)
            VERSION = theory_data.get("version", VERSION)
except Exception:
    pass


def extract_version_from_filename(filename: str) -> Optional[str]:
    """Extract version from filename like 'script_v15_0.py' -> '15.0'"""
    match = re.search(r'_v(\d+)_(\d+)\.py$', filename)
    if match:
        return f"{match.group(1)}.{match.group(2)}"

    match = re.search(r'_v(\d+)\.py$', filename)
    if match:
        return f"{match.group(1)}.0"

    return None


def extract_docstring_info(file_path: Path) -> Dict[str, Any]:
    """Extract description and status from Python docstring"""
    info = {
        "description": None,
        "status": None,
        "title": None
    }

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read(2000)  # Read first 2000 chars

            # Extract docstring
            docstring_match = re.search(r'"""(.+?)"""', content, re.DOTALL)
            if not docstring_match:
                docstring_match = re.search(r"'''(.+?)'''", content, re.DOTALL)

            if docstring_match:
                docstring = docstring_match.group(1).strip()
                lines = [line.strip() for line in docstring.split('\n') if line.strip()]

                # Extract title (first substantial line, often after "PRINCIPIA METAPHYSICA")
                for line in lines:
                    if line.startswith('PRINCIPIA METAPHYSICA'):
                        # Title is typically after the dash
                        if ' - ' in line:
                            info['title'] = line.split(' - ', 1)[1].strip()
                            break

                # Extract description (look for single-line summary)
                for line in lines:
                    # Skip header lines, separator lines, copyright
                    if any([
                        line.startswith('='),
                        line.startswith('-'),
                        line.startswith('PRINCIPIA'),
                        line.lower().startswith('copyright'),
                        line.lower().startswith('version'),
                        line.lower().startswith('v1'),
                        len(line) < 15  # Too short to be descriptive
                    ]):
                        continue

                    # First substantial line is the description
                    if not info['description'] and len(line) > 15:
                        info['description'] = line
                        break

                # Extract status keywords
                docstring_upper = docstring.upper()
                if 'STATUS: CORE' in docstring_upper or 'CORE VALIDATION' in docstring_upper:
                    info['status'] = 'CORE'
                elif 'STATUS: PREDICTION' in docstring_upper or 'TESTABLE PREDICTION' in docstring_upper:
                    info['status'] = 'PREDICTION'
                elif 'STATUS: VALIDATED' in docstring_upper or 'EXPERIMENTAL VALIDATION' in docstring_upper:
                    info['status'] = 'VALIDATED'
                elif 'STATUS: GEOMETRIC' in docstring_upper or 'GEOMETRIC DERIVATION' in docstring_upper:
                    info['status'] = 'GEOMETRIC'

    except Exception as e:
        print(f"Warning: Could not read {file_path}: {e}")

    return info


def categorize_by_path(rel_path: str) -> str:
    """Determine category from file path"""
    parts = Path(rel_path).parts

    if len(parts) > 1:
        subdir = parts[0].lower()

        # Map subdirectories to categories
        category_map = {
            'deprecated': 'Deprecated',
            'adhoc': 'Ad-Hoc / Experimental',
            'validation': 'Validation',
            'constants': 'Constants & Utilities',
            'core': 'Core Physics',
            'gauge': 'Gauge Unification',
            'neutrino': 'Neutrino Physics',
            'quantum': 'Quantum Biology',
            'cosmology': 'Cosmology',
            'geometry': 'G2 Geometry'
        }

        return category_map.get(subdir, 'Simulations')

    # Check filename for category hints
    filename_lower = Path(rel_path).name.lower()

    if any(word in filename_lower for word in ['gauge', 'gut', 'alpha']):
        return 'Gauge Unification'
    elif any(word in filename_lower for word in ['neutrino', 'pmns']):
        return 'Neutrino Physics'
    elif any(word in filename_lower for word in ['g2', 'metric', 'ricci', 'geometry']):
        return 'G2 Geometry'
    elif any(word in filename_lower for word in ['microtubule', 'quantum', 'biological']):
        return 'Quantum Biology'
    elif any(word in filename_lower for word in ['cosmology', 'dark', 'wz']):
        return 'Cosmology'
    elif any(word in filename_lower for word in ['moduli', 'flux', 'stabilization']):
        return 'Moduli Stabilization'
    elif any(word in filename_lower for word in ['yukawa', 'fermion', 'higgs']):
        return 'Yukawa & Fermion Masses'
    elif any(word in filename_lower for word in ['proton', 'decay']):
        return 'Proton Decay'
    elif any(word in filename_lower for word in ['kk', 'kaluza']):
        return 'KK Spectrum'

    return 'Simulations'


def generate_category_title(category: str) -> str:
    """Generate human-readable title for category"""
    return category


def scan_simulations_directory() -> Dict[str, Any]:
    """Scan simulations directory and build index"""

    index_data = {
        "version": VERSION,
        "generated": datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z'),
        "total_scripts": 0,
        "categories": {}
    }

    # Find all Python files in simulations directory
    all_scripts = []

    for py_file in SIMULATIONS_DIR.rglob("*.py"):
        # Skip __init__.py and files in __pycache__
        if py_file.name.startswith('__') or '__pycache__' in str(py_file):
            continue

        rel_path = py_file.relative_to(SIMULATIONS_DIR)

        # Extract metadata
        version = extract_version_from_filename(py_file.name)
        docstring_info = extract_docstring_info(py_file)
        category = categorize_by_path(str(rel_path))

        script_info = {
            "file": py_file.name,
            "path": f"simulations/{rel_path}".replace('\\', '/'),
            "version": version,
            "title": docstring_info.get('title'),
            "description": docstring_info.get('description') or "Physics simulation module",
            "status": docstring_info.get('status'),
            "category": category
        }

        all_scripts.append(script_info)

    # Group by category
    categories = {}
    for script in all_scripts:
        cat = script['category']
        if cat not in categories:
            categories[cat] = {
                "title": generate_category_title(cat),
                "path": f"simulations/",
                "scripts": [],
                "count": 0
            }

        categories[cat]['scripts'].append({
            "file": script['file'],
            "path": script['path'],
            "version": script['version'],
            "title": script['title'],
            "description": script['description'],
            "status": script['status']
        })
        categories[cat]['count'] += 1

    # Sort scripts within each category by version (descending)
    for cat_data in categories.values():
        cat_data['scripts'].sort(
            key=lambda s: (
                -float(s['version']) if s['version'] else 0,
                s['file']
            )
        )

    index_data['categories'] = categories
    index_data['total_scripts'] = len(all_scripts)

    return index_data


def main():
    """Main entry point"""
    print("=" * 60)
    print("PRINCIPIA METAPHYSICA - Simulations Index Generator")
    print("=" * 60)
    print(f"\nScanning directory: {SIMULATIONS_DIR}")
    print(f"Output file: {OUTPUT_FILE}\n")

    # Generate index
    index_data = scan_simulations_directory()

    # Write to file
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(index_data, f, indent=2, ensure_ascii=False)

    # Print summary
    print(f"[OK] Generated index with {index_data['total_scripts']} scripts")
    print(f"[OK] Organized into {len(index_data['categories'])} categories:\n")

    for cat_name, cat_data in sorted(index_data['categories'].items()):
        print(f"  - {cat_data['title']}: {cat_data['count']} scripts")

    print(f"\n[OK] Saved to: {OUTPUT_FILE}")
    print("\nDone!")


if __name__ == "__main__":
    main()
