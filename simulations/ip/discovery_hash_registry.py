#!/usr/bin/env python3
"""
Discovery Hash Registry for Intellectual Property Protection

This module creates a cryptographically verifiable record of key theoretical
predictions from the Principia Metaphysica theory. Each prediction is hashed
using SHA-512 (quantum-resistant) and timestamped with git commit information
to establish priority of discovery.

The hash registry serves as:
1. A tamper-evident record of when predictions were first computed
2. A verifiable chain of discovery for intellectual property claims
3. A permanent timestamp for priority in case of independent rediscovery

Author: Principia Metaphysica Research Team
Created: 2025-12-29
License: MIT (for the registry tool; theory content has separate IP status)

Copyright (c) 2025-2026 Andrew Keith Watts. All rights reserved.

Dedicated To:
    My Wife: Elizabeth May Watts
    Our Messiah: Jesus Of Nazareth
"""

import json
import hashlib
import subprocess
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, List, Optional


def generate_pm_master_hash():
    """
    Generate the Principia Metaphysica master hash using SHA-512.

    This hash cryptographically locks the core theoretical constants
    and provides quantum-resistant proof of discovery.

    Returns:
        str: SHA-512 hash of the core PM logic
    """
    core_logic = {
        "b3": 24,
        "k_gimel": 12.318309,
        "c_kaf": 27.2,
        "alpha_inv": 137.035999,
        "h0": 73.08,
        "version": "16.2",
        "timestamp": "2025-12-29"
    }

    logic_string = json.dumps(core_logic, sort_keys=True).encode()
    master_hash = hashlib.sha512(logic_string).hexdigest()
    return master_hash


class DiscoveryHashRegistry:
    """
    Manages cryptographic hashing and timestamping of theoretical predictions.
    """

    def __init__(self, repo_path: Path):
        """
        Initialize the registry.

        Args:
            repo_path: Path to the git repository root
        """
        self.repo_path = Path(repo_path)
        self.theory_output_path = self.repo_path / "AutoGenerated" / "theory_output.json"
        self.output_path = self.repo_path / "AutoGenerated" / "discovery_hashes.json"

    def get_git_info(self) -> Dict[str, str]:
        """
        Extract current git commit information.

        Returns:
            Dictionary with commit hash, branch, timestamp, and author
        """
        try:
            # Get commit hash
            commit_hash = subprocess.check_output(
                ["git", "-C", str(self.repo_path), "rev-parse", "HEAD"],
                text=True
            ).strip()

            # Get branch name
            branch = subprocess.check_output(
                ["git", "-C", str(self.repo_path), "rev-parse", "--abbrev-ref", "HEAD"],
                text=True
            ).strip()

            # Get commit timestamp
            commit_timestamp = subprocess.check_output(
                ["git", "-C", str(self.repo_path), "log", "-1", "--format=%aI", commit_hash],
                text=True
            ).strip()

            # Get commit author
            commit_author = subprocess.check_output(
                ["git", "-C", str(self.repo_path), "log", "-1", "--format=%an <%ae>", commit_hash],
                text=True
            ).strip()

            # Get commit message
            commit_message = subprocess.check_output(
                ["git", "-C", str(self.repo_path), "log", "-1", "--format=%s", commit_hash],
                text=True
            ).strip()

            return {
                "commit_hash": commit_hash,
                "short_hash": commit_hash[:8],
                "branch": branch,
                "timestamp": commit_timestamp,
                "author": commit_author,
                "message": commit_message
            }
        except subprocess.CalledProcessError as e:
            print(f"Warning: Could not get git info: {e}")
            return {
                "commit_hash": "unknown",
                "short_hash": "unknown",
                "branch": "unknown",
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "author": "unknown",
                "message": "unknown"
            }

    def compute_prediction_hash(self, prediction_data: Dict[str, Any]) -> str:
        """
        Compute SHA-512 hash of a prediction.

        The hash is computed over the canonical JSON representation to ensure
        reproducibility. SHA-512 provides quantum-resistant proof of work.
        The hash proves that this exact prediction was made at this exact time.

        Args:
            prediction_data: Dictionary containing the prediction details

        Returns:
            Hex string of SHA-512 hash
        """
        # Create canonical JSON representation (sorted keys, no whitespace)
        canonical_json = json.dumps(prediction_data, sort_keys=True, separators=(',', ':'))

        # Compute SHA-512 hash (quantum-resistant)
        hash_object = hashlib.sha512(canonical_json.encode('utf-8'))
        return hash_object.hexdigest()

    def load_theory_output(self) -> Dict[str, Any]:
        """
        Load the theory output JSON file.

        Returns:
            Theory output data
        """
        if not self.theory_output_path.exists():
            raise FileNotFoundError(f"Theory output not found: {self.theory_output_path}")

        with open(self.theory_output_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def extract_key_predictions(self, theory_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Extract the key novel predictions from theory output.

        These are the predictions that represent original intellectual contributions
        and should be timestamped for priority claims.

        Args:
            theory_data: Complete theory output

        Returns:
            List of key predictions with their data
        """
        parameters = theory_data.get("parameters", {})

        # Define key predictions to hash
        key_predictions = [
            {
                "name": "Dark Energy EOS Parameter w₀",
                "parameter_key": "cosmology.w0_derived",
                "prediction_type": "cosmological",
                "significance": "Derives w₀ = -11/13 ≈ -0.846 from dimensional reduction with 12-dimensional shadow spacetime. Testable prediction differing from ΛCDM (w₀ = -1).",
                "experimental_status": "DESI 2025 measures w₀ = -0.827 ± 0.063 (1.3σ from PM prediction)",
                "falsifiable": True,
                "priority_claim": "First derivation of dark energy EOS from G2 manifold geometry"
            },
            {
                "name": "Three Fermion Generations",
                "parameter_key": "fermion.n_generations",
                "prediction_type": "particle_physics",
                "significance": "Derives exactly 3 generations from topology: n_gen = N_flux / spinor_DOF = 24 / 8 = 3. Parameter-free prediction.",
                "experimental_status": "Matches observed 3 generations (PDG 2024)",
                "falsifiable": True,
                "priority_claim": "First topological derivation of generation count from TCS G2 manifold #187"
            },
            {
                "name": "Proton Lifetime",
                "parameter_key": "proton_decay.tau_p_years",
                "prediction_type": "particle_physics",
                "significance": "Predicts τ_p ≈ 4.8 × 10³⁴ years from GUT scale and geometric suppression. Testable by Hyper-Kamiokande.",
                "experimental_status": "Above Super-K bound (1.67 × 10³⁴ years). Awaiting Hyper-K measurements (2027+)",
                "falsifiable": True,
                "priority_claim": "First prediction of proton lifetime from G2 geometric suppression mechanism"
            },
            {
                "name": "GUT Unification Scale",
                "parameter_key": "gauge.M_GUT",
                "prediction_type": "particle_physics",
                "significance": "Derives M_GUT from geometric running of gauge couplings in G2 background.",
                "experimental_status": "Consistent with standard GUT predictions (~10¹⁶ GeV)",
                "falsifiable": True,
                "priority_claim": "GUT scale derived from G2 holonomy constraints"
            },
            {
                "name": "Cabibbo Angle from Geometry",
                "parameter_key": "ckm.V_us",
                "prediction_type": "particle_physics",
                "significance": "Predicts V_us = ε = exp(-λ) ≈ 0.223 from Froggatt-Nielsen suppression with λ = 1.5 (G2 curvature scale).",
                "experimental_status": "PDG 2024: 0.2257 ± 0.0009 (1.2% agreement, 2.9σ)",
                "falsifiable": True,
                "priority_claim": "First geometric derivation of Cabibbo angle from G2 curvature"
            },
            {
                "name": "Jarlskog Invariant (CP Violation)",
                "parameter_key": "ckm.jarlskog_invariant",
                "prediction_type": "particle_physics",
                "significance": "Predicts J ≈ 3 × 10⁻⁵ from topological CP phase arising from K=4 matching fibres in TCS construction.",
                "experimental_status": "PDG 2024: J = (3.0 ± 0.3) × 10⁻⁵ (within 3%)",
                "falsifiable": True,
                "priority_claim": "First topological origin of CP violation from TCS matching conditions"
            },
            {
                "name": "Yukawa Hierarchy Parameter",
                "parameter_key": "fermion.yukawa_hierarchy",
                "prediction_type": "particle_physics",
                "significance": "Derives ε = exp(-1.5) ≈ 0.223 from G2 curvature scale, explaining fermion mass hierarchy.",
                "experimental_status": "Explains observed hierarchies in quark and lepton masses",
                "falsifiable": True,
                "priority_claim": "Geometric origin of Yukawa hierarchy from G2 parallel transport"
            },
            {
                "name": "Chiral Asymmetry Index",
                "parameter_key": "chirality.chiral_index",
                "prediction_type": "particle_physics",
                "significance": "Derives chiral index = χ_eff/24 = 144/24 = 6 from Atiyah-Singer theorem on TCS G2 #187.",
                "experimental_status": "Topological prediction, connects to observed fermion spectrum",
                "falsifiable": True,
                "priority_claim": "First application of Atiyah-Singer index theorem to TCS G2 manifolds for SM chirality"
            },
            {
                "name": "GUT Coupling Constant",
                "parameter_key": "gauge.ALPHA_GUT",
                "prediction_type": "particle_physics",
                "significance": "Derives α_GUT from RG running in G2 background with geometric corrections.",
                "experimental_status": "Consistent with standard unification predictions",
                "falsifiable": True,
                "priority_claim": "G2 holonomy corrections to gauge coupling unification"
            },
            {
                "name": "Shadow Dimension Parameter",
                "parameter_key": "cosmology.D_eff",
                "prediction_type": "cosmological",
                "significance": "Derives D_eff from shadow spacetime breathing mode, connected to dark energy.",
                "experimental_status": "Indirectly testable through w₀ measurements",
                "falsifiable": True,
                "priority_claim": "Shadow spacetime dimension as source of dark energy"
            }
        ]

        # Extract parameter values for each prediction
        predictions_with_data = []
        for pred in key_predictions:
            param_key = pred["parameter_key"]
            if param_key in parameters:
                param_data = parameters[param_key]
                pred_data = {
                    **pred,
                    "value": param_data.get("value"),
                    "uncertainty": param_data.get("uncertainty"),
                    "units": param_data.get("metadata", {}).get("units", "dimensionless"),
                    "source_simulation": param_data.get("source_simulation"),
                    "computed_timestamp": param_data.get("timestamp"),
                    "git_commit_at_computation": param_data.get("git_commit")
                }
                predictions_with_data.append(pred_data)
            else:
                print(f"Warning: Parameter {param_key} not found in theory output")

        return predictions_with_data

    def create_discovery_registry(self) -> Dict[str, Any]:
        """
        Create the complete discovery hash registry.

        Returns:
            Registry data structure with hashes and timestamps
        """
        # Load theory output
        print("Loading theory output...")
        theory_data = self.load_theory_output()

        # Get git information
        print("Extracting git information...")
        git_info = self.get_git_info()

        # Extract key predictions
        print("Extracting key predictions...")
        predictions = self.extract_key_predictions(theory_data)

        # Create registry entries
        print("Computing cryptographic hashes...")
        registry_entries = []
        for pred in predictions:
            # Create prediction record (what we're hashing)
            prediction_record = {
                "name": pred["name"],
                "parameter_key": pred["parameter_key"],
                "value": pred["value"],
                "units": pred["units"],
                "uncertainty": pred["uncertainty"],
                "prediction_type": pred["prediction_type"],
                "significance": pred["significance"]
            }

            # Compute hash
            discovery_hash = self.compute_prediction_hash(prediction_record)

            # Create registry entry
            entry = {
                "discovery_hash": discovery_hash,
                "short_hash": discovery_hash[:16],
                "prediction": prediction_record,
                "priority_claim": pred["priority_claim"],
                "experimental_status": pred["experimental_status"],
                "falsifiable": pred["falsifiable"],
                "timestamps": {
                    "first_computed": pred["computed_timestamp"],
                    "registry_created": datetime.now(timezone.utc).isoformat(),
                    "git_commit": pred["git_commit_at_computation"]
                },
                "verification": {
                    "algorithm": "SHA-512",
                    "canonical_format": "JSON (sorted keys, no whitespace)",
                    "reproducible": True,
                    "quantum_resistant": True,
                    "instructions": "Hash the 'prediction' field using SHA-512 to verify"
                }
            }

            registry_entries.append(entry)

        # Create complete registry
        registry = {
            "metadata": {
                "title": "Principia Metaphysica Discovery Hash Registry",
                "version": "1.0",
                "created": datetime.now(timezone.utc).isoformat(),
                "description": "Cryptographic hash registry for intellectual property protection of key theoretical predictions",
                "purpose": [
                    "Establish priority of discovery",
                    "Create tamper-evident record of predictions",
                    "Enable independent verification of claims",
                    "Protect intellectual property rights"
                ],
                "license": "Registry format: MIT; Theory content: See DISCOVERY_PRIORITY.md"
            },
            "git_snapshot": {
                **git_info,
                "repository": "https://github.com/[username]/PrincipiaMetaphysica",
                "theory_file": "AutoGenerated/theory_output.json",
                "note": "All hashes computed from this git commit state"
            },
            "discoveries": registry_entries,
            "statistics": {
                "total_predictions": len(registry_entries),
                "falsifiable_count": sum(1 for e in registry_entries if e["falsifiable"]),
                "prediction_types": list(set(e["prediction"]["prediction_type"] for e in registry_entries))
            },
            "verification_protocol": {
                "step_1": "Clone the repository at the specified git commit",
                "step_2": "Load AutoGenerated/theory_output.json",
                "step_3": "Extract the prediction field from each entry",
                "step_4": "Compute SHA-512 hash of canonical JSON (sorted keys)",
                "step_5": "Compare with discovery_hash field",
                "note": "All hashes must match to verify registry integrity",
                "quantum_resistance": "SHA-512 provides enhanced security against quantum attacks"
            }
        }

        return registry

    def save_registry(self, registry: Dict[str, Any]) -> None:
        """
        Save the registry to JSON file.

        Args:
            registry: Registry data structure
        """
        self.output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(self.output_path, 'w', encoding='utf-8') as f:
            json.dump(registry, f, indent=2, ensure_ascii=False)

        print(f"\n[OK] Registry saved to: {self.output_path}")

    def print_summary(self, registry: Dict[str, Any]) -> None:
        """
        Print a summary of the registry.

        Args:
            registry: Registry data structure
        """
        # Use ASCII-safe output
        print("\n" + "="*80)
        print("DISCOVERY HASH REGISTRY SUMMARY")
        print("="*80)
        print(f"\nRegistry Version: {registry['metadata']['version']}")
        print(f"Created: {registry['metadata']['created']}")
        print(f"Git Commit: {registry['git_snapshot']['short_hash']} ({registry['git_snapshot']['branch']})")
        print(f"\nTotal Predictions: {registry['statistics']['total_predictions']}")
        print(f"Falsifiable: {registry['statistics']['falsifiable_count']}")
        print(f"Types: {', '.join(registry['statistics']['prediction_types'])}")

        print("\n" + "-"*80)
        print("KEY PREDICTIONS")
        print("-"*80)

        for i, entry in enumerate(registry['discoveries'], 1):
            pred = entry['prediction']
            # Convert Unicode to ASCII-safe representation
            name = pred['name'].encode('ascii', 'replace').decode('ascii')
            units = pred['units'].encode('ascii', 'replace').decode('ascii')
            priority = entry['priority_claim'].encode('ascii', 'replace').decode('ascii')
            status = entry['experimental_status'].encode('ascii', 'replace').decode('ascii')

            print(f"\n{i}. {name}")
            print(f"   Hash: {entry['short_hash']}...")
            print(f"   Value: {pred['value']} {units}")
            print(f"   Priority: {priority[:60]}...")
            print(f"   Status: {status[:60]}...")

        print("\n" + "="*80)


def main():
    """Main entry point."""
    print("Principia Metaphysica - Discovery Hash Registry Generator")
    print("="*80)

    # Initialize registry
    repo_path = Path(__file__).parent.parent.parent
    registry = DiscoveryHashRegistry(repo_path)

    # Create registry
    registry_data = registry.create_discovery_registry()

    # Save to file
    registry.save_registry(registry_data)

    # Print summary
    registry.print_summary(registry_data)

    print("\n[OK] Discovery hash registry generation complete!")
    print(f"[OK] Output: {registry.output_path}")
    print("\nNext steps:")
    print("1. Review AutoGenerated/discovery_hashes.json")
    print("2. Read DISCOVERY_PRIORITY.md for usage instructions")
    print("3. Consider publishing hashes to a blockchain for additional timestamping")
    print("4. Keep this registry updated as new predictions are made")


if __name__ == "__main__":
    main()
