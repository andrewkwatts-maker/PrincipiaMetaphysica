"""
Post-Processing Validation for Principia Metaphysica
======================================================

Comprehensive validation suite for theory_output.json integrity:
1. Validates completeness of parameter and formula references
2. Checks bidirectional links between formulas and parameters
3. Builds simulation dependency graphs and detects cycles
4. Validates predictions against experimental bounds
5. Generates detailed validation reports

Usage:
    from simulations.post_processing import generate_full_report

    # Generate comprehensive validation report
    generate_full_report(
        registry=None,  # Will auto-load
        output_path="validation_report.json"
    )

    # Or run individual checks
    from simulations.post_processing import validate_theory_output
    report = validate_theory_output("AutoGenerated/theory_output.json")
    print(report)

Copyright (c) 2025-2026 Andrew Keith Watts. All rights reserved.

Dedicated To:
    My Wife: Elizabeth May Watts
    Our Messiah: Jesus Of Nazareth
"""

import json
import os
import sys
from dataclasses import dataclass, field, asdict
from typing import Dict, Any, List, Optional, Set, Tuple
from collections import defaultdict, deque
from datetime import datetime
import warnings

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from simulations.base import (
        PMRegistry,
        ValidationResult,
        SimulationValidator,
        RegistryValidator,
    )
    from simulations.base.formulas import FormulaRegistry, FormulaCategory
    from simulations.base.sections import SectionRegistry
    IMPORTS_AVAILABLE = True
except ImportError as e:
    warnings.warn(f"Could not import base modules: {e}")
    IMPORTS_AVAILABLE = False


# ============================================================================
# Data Structures
# ============================================================================

@dataclass
class ParameterStatus:
    """Status information for a parameter."""
    path: str
    exists: bool
    status: str  # ESTABLISHED, GEOMETRIC, DERIVED, PREDICTED, CALIBRATED
    source: str
    value: Any
    has_provenance: bool
    referenced_by_formulas: List[str] = field(default_factory=list)
    referenced_by_sections: List[str] = field(default_factory=list)
    issues: List[str] = field(default_factory=list)


@dataclass
class FormulaStatus:
    """Status information for a formula."""
    id: str
    exists: bool
    category: str
    section_id: str
    label: str
    input_params_valid: bool
    output_params_valid: bool
    missing_inputs: List[str] = field(default_factory=list)
    missing_outputs: List[str] = field(default_factory=list)
    orphaned_outputs: List[str] = field(default_factory=list)
    issues: List[str] = field(default_factory=list)


@dataclass
class SectionCoverage:
    """Coverage information for a section."""
    section_id: str
    title: str
    has_content: bool
    formula_count: int
    param_count: int
    formula_refs: List[str] = field(default_factory=list)
    param_refs: List[str] = field(default_factory=list)
    missing_formulas: List[str] = field(default_factory=list)
    missing_params: List[str] = field(default_factory=list)
    orphaned_formulas: List[str] = field(default_factory=list)  # In registry but not referenced


@dataclass
class BoundCheck:
    """Experimental bound validation check."""
    param_path: str
    computed_value: float
    bound_value: float
    bound_type: str  # upper, lower, range, measured
    bound_source: str
    sigma_deviation: float
    passed: bool
    units: str
    notes: str = ""


@dataclass
class DependencyNode:
    """Node in the simulation dependency graph."""
    simulation_id: str
    required_inputs: List[str]
    output_params: List[str]
    output_formulas: List[str]
    dependencies: List[str] = field(default_factory=list)  # Other simulations required
    execution_order: int = -1  # Topological sort order


@dataclass
class ValidationReport:
    """Comprehensive validation report."""
    timestamp: str
    theory_output_path: str
    version: str

    # Summary counts
    total_parameters: int = 0
    total_formulas: int = 0
    total_sections: int = 0
    total_simulations: int = 0

    # Status counts
    parameters_ok: int = 0
    parameters_with_issues: int = 0
    formulas_ok: int = 0
    formulas_with_issues: int = 0
    sections_with_content: int = 0
    sections_without_content: int = 0

    # Detailed results
    parameter_status: List[ParameterStatus] = field(default_factory=list)
    formula_status: List[FormulaStatus] = field(default_factory=list)
    section_coverage: List[SectionCoverage] = field(default_factory=list)
    bound_checks: List[BoundCheck] = field(default_factory=list)
    dependency_graph: Dict[str, DependencyNode] = field(default_factory=dict)

    # Issues
    critical_errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    orphaned_params: List[str] = field(default_factory=list)
    orphaned_formulas: List[str] = field(default_factory=list)
    circular_dependencies: List[List[str]] = field(default_factory=list)

    # Additional metadata
    execution_order: List[str] = field(default_factory=list)  # Recommended simulation order

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return asdict(self)

    def summary(self) -> str:
        """Generate a text summary of the validation."""
        lines = [
            "=" * 80,
            "PRINCIPIA METAPHYSICA VALIDATION REPORT",
            "=" * 80,
            f"Generated: {self.timestamp}",
            f"Theory Output: {self.theory_output_path}",
            f"Version: {self.version}",
            "",
            "SUMMARY",
            "-" * 80,
            f"Parameters:   {self.parameters_ok}/{self.total_parameters} OK "
            f"({self.parameters_with_issues} with issues)",
            f"Formulas:     {self.formulas_ok}/{self.total_formulas} OK "
            f"({self.formulas_with_issues} with issues)",
            f"Sections:     {self.sections_with_content}/{self.total_sections} with content",
            f"Simulations:  {self.total_simulations} registered",
            "",
        ]

        if self.critical_errors:
            lines.extend([
                f"CRITICAL ERRORS: {len(self.critical_errors)}",
                "-" * 80,
            ])
            for error in self.critical_errors[:10]:  # Show first 10
                lines.append(f"  - {error}")
            if len(self.critical_errors) > 10:
                lines.append(f"  ... and {len(self.critical_errors) - 10} more")
            lines.append("")

        if self.warnings:
            lines.extend([
                f"WARNINGS: {len(self.warnings)}",
                "-" * 80,
            ])
            for warning in self.warnings[:10]:
                lines.append(f"  - {warning}")
            if len(self.warnings) > 10:
                lines.append(f"  ... and {len(self.warnings) - 10} more")
            lines.append("")

        if self.circular_dependencies:
            lines.extend([
                f"CIRCULAR DEPENDENCIES: {len(self.circular_dependencies)}",
                "-" * 80,
            ])
            for cycle in self.circular_dependencies:
                lines.append(f"  - {' -> '.join(cycle)}")
            lines.append("")

        if self.orphaned_params:
            lines.append(f"Orphaned Parameters: {len(self.orphaned_params)}")
        if self.orphaned_formulas:
            lines.append(f"Orphaned Formulas: {len(self.orphaned_formulas)}")

        lines.extend([
            "",
            "=" * 80,
        ])

        return "\n".join(lines)


# ============================================================================
# Core Validation Functions
# ============================================================================

def validate_theory_output(json_path: str) -> ValidationReport:
    """
    Validate theory_output.json for completeness and consistency.

    Checks:
    - All paramRefs in sections point to computed parameters
    - All formulaRefs in sections point to defined formulas
    - Bidirectional links (formula.outputParams exist in parameters)
    - All DERIVED params have provenance
    - No orphaned parameters or formulas

    Args:
        json_path: Path to theory_output.json

    Returns:
        ValidationReport with detailed findings
    """
    report = ValidationReport(
        timestamp=datetime.now().isoformat(),
        theory_output_path=json_path,
        version="unknown"
    )

    # Check if file exists
    if not os.path.exists(json_path):
        report.critical_errors.append(f"theory_output.json not found at {json_path}")
        return report

    # Load JSON
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        report.critical_errors.append(f"Failed to load JSON: {e}")
        return report

    report.version = data.get('version', 'unknown')

    # Extract data sections
    simulations = data.get('simulations', {})
    parameters = data.get('parameters', {})
    formulas = data.get('formulas', {})
    sections = data.get('sections', {})

    report.total_simulations = len(simulations)
    report.total_parameters = len(parameters)
    report.total_formulas = len(formulas)
    report.total_sections = len(sections)

    # Build reference maps
    param_to_formulas = defaultdict(list)  # param_path -> [formula_ids]
    param_to_sections = defaultdict(list)  # param_path -> [section_ids]
    formula_to_sections = defaultdict(list)  # formula_id -> [section_ids]

    # Scan sections for references
    for section_id, section_data in sections.items():
        param_refs = section_data.get('paramRefs', [])
        formula_refs = section_data.get('formulaRefs', [])

        for param_path in param_refs:
            param_to_sections[param_path].append(section_id)

        for formula_id in formula_refs:
            formula_to_sections[formula_id].append(section_id)

    # Scan formulas for parameter references
    for formula_id, formula_data in formulas.items():
        input_params = formula_data.get('inputParams', [])
        output_params = formula_data.get('outputParams', [])

        for param_path in input_params + output_params:
            param_to_formulas[param_path].append(formula_id)

    # Validate parameters
    for param_path, param_data in parameters.items():
        status = ParameterStatus(
            path=param_path,
            exists=True,
            status=param_data.get('status', 'UNKNOWN'),
            source=param_data.get('source', 'UNKNOWN'),
            value=param_data.get('value'),
            has_provenance=bool(param_data.get('source')),
            referenced_by_formulas=param_to_formulas.get(param_path, []),
            referenced_by_sections=param_to_sections.get(param_path, [])
        )

        # Check for issues
        if status.status == "DERIVED" and not status.has_provenance:
            status.issues.append("DERIVED parameter missing provenance/source")

        if not status.referenced_by_formulas and not status.referenced_by_sections:
            status.issues.append("Orphaned: not referenced by any formula or section")
            report.orphaned_params.append(param_path)

        if status.value is None:
            status.issues.append("Parameter has no computed value")

        report.parameter_status.append(status)

        if status.issues:
            report.parameters_with_issues += 1
            for issue in status.issues:
                report.warnings.append(f"Parameter {param_path}: {issue}")
        else:
            report.parameters_ok += 1

    # Validate formulas
    for formula_id, formula_data in formulas.items():
        status = FormulaStatus(
            id=formula_id,
            exists=True,
            category=formula_data.get('category', 'UNKNOWN'),
            section_id=formula_data.get('sectionId', 'UNKNOWN'),
            label=formula_data.get('label', formula_data.get('equationNumber', 'UNKNOWN'))
        )

        input_params = formula_data.get('inputParams', [])
        output_params = formula_data.get('outputParams', [])

        # Check input parameters exist
        for param_path in input_params:
            if param_path not in parameters:
                status.missing_inputs.append(param_path)
                status.input_params_valid = False
            else:
                status.input_params_valid = True

        # Check output parameters exist
        for param_path in output_params:
            if param_path not in parameters:
                status.missing_outputs.append(param_path)
                status.output_params_valid = False
            else:
                status.output_params_valid = True

                # Verify bidirectional link
                param_data = parameters[param_path]
                derivation_formula = param_data.get('derivationFormula')
                if derivation_formula != formula_id:
                    status.orphaned_outputs.append(
                        f"{param_path} (derivationFormula={derivation_formula})"
                    )

        # Check if formula is referenced by any section
        if not formula_to_sections.get(formula_id):
            status.issues.append("Orphaned: not referenced by any section")
            report.orphaned_formulas.append(formula_id)

        # Compile issues
        if status.missing_inputs:
            status.issues.append(f"Missing input params: {status.missing_inputs}")
        if status.missing_outputs:
            status.issues.append(f"Missing output params: {status.missing_outputs}")
        if status.orphaned_outputs:
            status.issues.append(f"Bidirectional link broken: {status.orphaned_outputs}")

        report.formula_status.append(status)

        if status.issues:
            report.formulas_with_issues += 1
            for issue in status.issues:
                report.warnings.append(f"Formula {formula_id}: {issue}")
        else:
            report.formulas_ok += 1

    # Validate section coverage
    section_registry = SectionRegistry(load_from_json=False)
    all_sections = section_registry.get_all_sections()

    for section_id, section_info in all_sections.items():
        section_data = sections.get(section_id, {})

        formula_refs = section_data.get('formulaRefs', [])
        param_refs = section_data.get('paramRefs', [])

        coverage = SectionCoverage(
            section_id=section_id,
            title=section_info.title,
            has_content=section_id in sections,
            formula_count=len(formula_refs),
            param_count=len(param_refs),
            formula_refs=formula_refs,
            param_refs=param_refs
        )

        # Check for missing references
        for formula_id in formula_refs:
            if formula_id not in formulas:
                coverage.missing_formulas.append(formula_id)

        for param_path in param_refs:
            if param_path not in parameters:
                coverage.missing_params.append(param_path)

        # Check for orphaned formulas in this section
        for formula_id, formula_data in formulas.items():
            if formula_data.get('sectionId') == section_id:
                if formula_id not in formula_refs:
                    coverage.orphaned_formulas.append(formula_id)

        report.section_coverage.append(coverage)

        if coverage.has_content:
            report.sections_with_content += 1
        else:
            report.sections_without_content += 1

    # Build dependency graph
    report.dependency_graph = build_dependency_graph(simulations)

    # Check for circular dependencies
    report.circular_dependencies = detect_circular_dependencies(report.dependency_graph)

    # Compute execution order
    if not report.circular_dependencies:
        report.execution_order = topological_sort(report.dependency_graph)
    else:
        report.critical_errors.append(
            f"Cannot compute execution order: {len(report.circular_dependencies)} circular dependencies"
        )

    return report


def build_dependency_graph(simulations: Dict[str, Any]) -> Dict[str, DependencyNode]:
    """
    Build directed acyclic graph (DAG) from simulation dependencies.

    Args:
        simulations: Simulations data from theory_output.json

    Returns:
        Dictionary mapping simulation IDs to DependencyNode
    """
    graph: Dict[str, DependencyNode] = {}

    # First pass: create nodes
    for sim_id, sim_data in simulations.items():
        node = DependencyNode(
            simulation_id=sim_id,
            required_inputs=sim_data.get('required_inputs', []),
            output_params=sim_data.get('output_params', []),
            output_formulas=sim_data.get('output_formulas', [])
        )
        graph[sim_id] = node

    # Second pass: determine dependencies
    # A simulation depends on another if it requires that simulation's outputs
    for sim_id, node in graph.items():
        dependencies = set()

        for required_param in node.required_inputs:
            # Find which simulation produces this parameter
            for other_id, other_node in graph.items():
                if other_id == sim_id:
                    continue
                if required_param in other_node.output_params:
                    dependencies.add(other_id)

        node.dependencies = list(dependencies)

    return graph


def detect_circular_dependencies(
    graph: Dict[str, DependencyNode]
) -> List[List[str]]:
    """
    Detect circular dependencies using depth-first search.

    Args:
        graph: Dependency graph

    Returns:
        List of cycles (each cycle is a list of simulation IDs)
    """
    cycles = []
    visited = set()
    rec_stack = set()
    path = []

    def dfs(node_id: str) -> bool:
        """DFS helper that returns True if cycle detected."""
        visited.add(node_id)
        rec_stack.add(node_id)
        path.append(node_id)

        node = graph.get(node_id)
        if node:
            for dep_id in node.dependencies:
                if dep_id not in visited:
                    if dfs(dep_id):
                        return True
                elif dep_id in rec_stack:
                    # Found a cycle
                    cycle_start = path.index(dep_id)
                    cycle = path[cycle_start:] + [dep_id]
                    cycles.append(cycle)
                    return True

        path.pop()
        rec_stack.remove(node_id)
        return False

    for node_id in graph:
        if node_id not in visited:
            dfs(node_id)

    return cycles


def topological_sort(graph: Dict[str, DependencyNode]) -> List[str]:
    """
    Topological sort using Kahn's algorithm.

    Args:
        graph: Dependency graph (must be acyclic)

    Returns:
        List of simulation IDs in execution order
    """
    # Calculate in-degrees
    in_degree = {node_id: 0 for node_id in graph}

    for node in graph.values():
        for dep_id in node.dependencies:
            if dep_id in in_degree:
                in_degree[dep_id] += 1

    # Queue of nodes with no incoming edges
    queue = deque([node_id for node_id, degree in in_degree.items() if degree == 0])
    sorted_order = []

    while queue:
        node_id = queue.popleft()
        sorted_order.append(node_id)

        # For each node that depends on this one
        node = graph[node_id]
        for dep_id in node.dependencies:
            in_degree[dep_id] -= 1
            if in_degree[dep_id] == 0:
                queue.append(dep_id)

    # If not all nodes processed, there's a cycle
    if len(sorted_order) != len(graph):
        return []

    return sorted_order


def check_param_coverage(theory_output: Dict[str, Any]) -> Dict[str, Any]:
    """
    Analyze parameter coverage across the theory.

    Args:
        theory_output: Loaded theory_output.json data

    Returns:
        Dictionary with coverage statistics
    """
    parameters = theory_output.get('parameters', {})

    by_status = defaultdict(int)
    by_source = defaultdict(int)
    with_uncertainty = 0
    without_value = 0

    for param_path, param_data in parameters.items():
        status = param_data.get('status', 'UNKNOWN')
        source = param_data.get('source', 'UNKNOWN')

        by_status[status] += 1
        by_source[source] += 1

        if param_data.get('uncertainty') is not None:
            with_uncertainty += 1

        if param_data.get('value') is None:
            without_value += 1

    return {
        'total': len(parameters),
        'by_status': dict(by_status),
        'by_source': dict(by_source),
        'with_uncertainty': with_uncertainty,
        'without_value': without_value,
    }


def check_formula_coverage(theory_output: Dict[str, Any]) -> Dict[str, Any]:
    """
    Analyze formula coverage across the theory.

    Args:
        theory_output: Loaded theory_output.json data

    Returns:
        Dictionary with coverage statistics
    """
    formulas = theory_output.get('formulas', {})

    by_category = defaultdict(int)
    by_section = defaultdict(int)
    validated = 0
    with_derivation = 0

    for formula_id, formula_data in formulas.items():
        category = formula_data.get('category', 'UNKNOWN')
        section = formula_data.get('sectionId', 'UNKNOWN')

        by_category[category] += 1

        # Extract main section number
        if section and '.' in section:
            section = section.split('.')[0]
        by_section[section] += 1

        if formula_data.get('validated'):
            validated += 1

        derivation = formula_data.get('derivation')
        if derivation and (
            derivation.get('parentFormulas') or
            derivation.get('steps') or
            derivation.get('method')
        ):
            with_derivation += 1

    return {
        'total': len(formulas),
        'by_category': dict(by_category),
        'by_section': dict(by_section),
        'validated': validated,
        'with_derivation': with_derivation,
    }


def validate_predictions(registry: Optional['PMRegistry'] = None) -> List[BoundCheck]:
    """
    Validate all PREDICTED parameters against experimental bounds.

    Args:
        registry: PMRegistry instance (will create if None)

    Returns:
        List of BoundCheck objects
    """
    if registry is None:
        if not IMPORTS_AVAILABLE:
            warnings.warn("Cannot validate predictions: imports not available")
            return []
        registry = PMRegistry.get_instance()

    bound_checks = []

    # Get all parameters
    params_data = registry.export_parameters()

    for param_path, param_info in params_data.items():
        status = param_info.get('status')
        if status not in ['DERIVED', 'PREDICTED', 'CALIBRATED']:
            continue

        metadata = param_info.get('metadata', {})
        bound = metadata.get('experimental_bound')
        bound_type = metadata.get('bound_type')
        bound_source = metadata.get('bound_source', 'Unknown')

        if bound is None or bound_type is None:
            continue

        value = param_info.get('value')
        uncertainty = param_info.get('uncertainty', 0)

        if value is None:
            continue

        # Calculate sigma deviation
        if uncertainty > 0:
            if bound_type == 'measured':
                sigma = abs(value - bound) / uncertainty
            else:
                sigma = 0.0
        else:
            sigma = 0.0

        # Check bound
        passed = True
        notes = ""

        if bound_type == 'lower':
            passed = value >= bound
            notes = f"{'Above' if passed else 'Below'} lower bound"
        elif bound_type == 'upper':
            passed = value <= bound
            notes = f"{'Below' if passed else 'Above'} upper bound"
        elif bound_type == 'measured':
            # Within 3 sigma is acceptable
            passed = sigma <= 3.0
            notes = f"{sigma:.2f} sigma from experimental value"

        check = BoundCheck(
            param_path=param_path,
            computed_value=value,
            bound_value=bound,
            bound_type=bound_type,
            bound_source=bound_source,
            sigma_deviation=sigma,
            passed=passed,
            units=metadata.get('units', ''),
            notes=notes
        )

        bound_checks.append(check)

    return bound_checks


def generate_full_report(
    registry: Optional['PMRegistry'] = None,
    output_path: Optional[str] = None
) -> ValidationReport:
    """
    Generate comprehensive validation report.

    This is the main entry point for validation. It runs all checks
    and generates a detailed report.

    Args:
        registry: PMRegistry instance (will load if None)
        output_path: Path to save JSON report (optional)

    Returns:
        ValidationReport with all findings
    """
    # Determine theory_output.json path
    theory_output_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "AutoGenerated", "theory_output.json"
    )

    # Run main validation
    report = validate_theory_output(theory_output_path)

    # Add prediction validation if registry available
    if IMPORTS_AVAILABLE:
        try:
            if registry is None:
                registry = PMRegistry.get_instance()

            report.bound_checks = validate_predictions(registry)

            # Count bound check results
            passed = sum(1 for check in report.bound_checks if check.passed)
            failed = len(report.bound_checks) - passed

            if failed > 0:
                report.warnings.append(
                    f"{failed}/{len(report.bound_checks)} bound checks failed"
                )
        except Exception as e:
            report.warnings.append(f"Could not validate predictions: {e}")

    # Save to file if requested
    if output_path:
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report.to_dict(), f, indent=2)
            print(f"Report saved to {output_path}")
        except Exception as e:
            report.warnings.append(f"Could not save report to {output_path}: {e}")

    return report


# ============================================================================
# CLI Interface
# ============================================================================

def main():
    """Command-line interface for post-processing validation."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Principia Metaphysica Post-Processing Validation"
    )
    parser.add_argument(
        '--output', '-o',
        default='validation_report.json',
        help='Output path for JSON report'
    )
    parser.add_argument(
        '--summary', '-s',
        action='store_true',
        help='Print text summary to console'
    )
    parser.add_argument(
        '--theory-output', '-t',
        default=None,
        help='Path to theory_output.json (default: AutoGenerated/theory_output.json)'
    )

    args = parser.parse_args()

    print("=" * 80)
    print("Principia Metaphysica Post-Processing Validation")
    print("=" * 80)
    print()

    # Generate report
    print("Running validation checks...")
    report = generate_full_report(output_path=args.output)

    # Print summary
    if args.summary or True:  # Always print summary
        print()
        print(report.summary())

    print()
    print(f"Full report saved to: {args.output}")
    print()

    # Exit with error code if critical errors found
    if report.critical_errors:
        sys.exit(1)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()
