"""
Validate Parameter References in HTML Files
============================================

Scans all HTML files for parameter references (data-pm-value, pm-param, data-category)
and validates they resolve to actual values in theory_output.json.

Usage:
    python validate_param_references.py

Copyright (c) 2025-2026 Andrew Keith Watts. All rights reserved.

Dedicated To:
    My Wife: Elizabeth May Watts
    Our Messiah: Jesus Of Nazareth
"""

import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Any, Set, Tuple


# Parameter aliases (must match pm-constants-loader.js)
PARAMETER_ALIASES = {
    # Note: dimensions.X paths are handled by built-in fallback
    # Only map dimension aliases that need special handling
    'dimensions.d_g2': 'dimensions.D_G2',

    # Topology
    'topology.elder_kads': 'parameters.topology.B3',
    'topology.b2': 'parameters.topology.B2',
    'topology.mephorash_chi': 'parameters.topology.CHI_EFF',
    'topology.n_gen': 'parameters.topology.n_gen',

    # KK spectrum
    'kk_spectrum.m1_central': 'simulations.kk_graviton.m_KK_TeV',
    'kk_spectrum.m1_tev': 'simulations.kk_graviton.m_KK_TeV',
    'kk_spectrum.hl_lhc_significance': 'simulations.kk_graviton.hl_lhc_discovery',

    # Proton decay
    'proton_decay.tau_p_years': 'simulations.proton_decay.tau_p_years',
    'proton_decay.alpha_gut_inv': 'simulations.proton_decay.alpha_gut_inv',
    'proton_decay.m_gut': 'parameters.gauge.M_GUT',

    # Higgs
    'higgs_mass.m_h_gev': 'simulations.higgs_mass.m_h_GeV',
    'v11_final_observables.higgs_mass.m_h_gev': 'simulations.higgs_mass.m_h_GeV',
    'v11_final_observables.proton_lifetime.tau_p_years': 'simulations.proton_decay.tau_p_years',

    # Dark energy
    'dark_energy.w0': 'parameters.dark_energy.w0',
    'dark_energy.w0_pm': 'parameters.dark_energy.w0',

    # Validation -> Framework Statistics
    'validation.predictions_within_1sigma': 'framework_statistics.within_1_sigma',
    'validation.within_1_sigma': 'framework_statistics.within_1_sigma',
    'validation.predictions_within_2sigma': 'framework_statistics.within_2_sigma',
    'validation.total_sm_parameters': 'framework_statistics.total_sm_parameters',
    'validation.total_predictions': 'framework_statistics.total_sm_parameters',
    'validation.exact_matches': 'framework_statistics.exact_matches',

    # PMNS angles (in parameters.pmns, not simulations)
    'pmns_matrix.theta_23': 'parameters.pmns.theta_23',
    'pmns_matrix.theta_12': 'parameters.pmns.theta_12',
    'pmns_matrix.theta_13': 'parameters.pmns.theta_13',
    'pmns_matrix.delta_cp': 'parameters.pmns.delta_CP',

    # Neutrino masses
    'neutrino_mass.delta_m_sq': 'simulations.neutrino_masses.delta_m21_sq',
    'neutrino_masses.delta_m21_sq': 'simulations.neutrino_masses.delta_m21_sq',
    'neutrino_masses.delta_m3l_sq': 'simulations.neutrino_masses.delta_m3l_sq',

    # KK graviton
    'kk_graviton.mass_tev': 'simulations.kk_graviton.m_KK_TeV',

    # VEV / Higgs
    'v12_6_geometric_derivations.vev_pneuma.v_ew': 'parameters.electroweak.v_higgs',
    'electroweak.v_higgs': 'parameters.electroweak.v_higgs',
}

# Built-in fallback values (must match pm-constants-loader.js)
BUILTIN_DIMENSIONS = {
    'D_BULK': 26,
    'D_AFTER_SP2R': 13,
    'D_G2': 7,
    'D_SPIN8': 8,         # Octonions dimension (Spin(8) triality)
    'D_OBSERVABLE': 4,
    'D_COMMON': 4
}

BUILTIN_ELECTROWEAK = {
    'v_higgs': 246.22,
    'v_ew': 246.22,
    'm_z': 91.1876,
    'm_w': 80.377
}


def load_theory_output(base_dir: Path) -> Dict[str, Any]:
    """Load theory_output.json from AutoGenerated folder."""
    paths = [
        base_dir / 'AutoGenerated' / 'theory_output.json',
        base_dir / 'theory_output.json'
    ]

    for path in paths:
        if path.exists():
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)

    raise FileNotFoundError("Could not find theory_output.json")


def resolve_alias(path: str) -> str:
    """Resolve parameter alias to actual path."""
    normalized = path.lower()
    for alias, real_path in PARAMETER_ALIASES.items():
        if normalized == alias.lower():
            return real_path
    return path


def get_value_by_path(data: Dict[str, Any], path: str) -> Tuple[Any, bool]:
    """
    Get value by dotted path with case-insensitive fallback.
    Returns (value, found) tuple.
    """
    # Resolve alias first
    path = resolve_alias(path)
    parts = path.split('.')

    # Check built-in dimensions (case-insensitive)
    if parts[0].lower() == 'dimensions' and len(parts) == 2:
        dim_key = parts[1].upper()
        # Handle underscore variations
        if dim_key not in BUILTIN_DIMENSIONS:
            # Try without 'D_' prefix if present
            if dim_key.startswith('D_'):
                alt_key = dim_key
            else:
                alt_key = 'D_' + dim_key
            if alt_key in BUILTIN_DIMENSIONS:
                dim_key = alt_key
        if dim_key in BUILTIN_DIMENSIONS:
            return BUILTIN_DIMENSIONS[dim_key], True

    # Check built-in electroweak
    if parts[0] in ('electroweak', 'parameters') and 'electroweak' in path.lower():
        ew_key = parts[-1].lower()
        if ew_key == 'value' and len(parts) > 2:
            ew_key = parts[-2].lower()
        if ew_key in BUILTIN_ELECTROWEAK:
            return BUILTIN_ELECTROWEAK[ew_key], True

    # Try exact path
    value = data
    for part in parts:
        if isinstance(value, dict):
            if part in value:
                value = value[part]
            else:
                # Try case-insensitive
                found = False
                for key in value.keys():
                    if key.lower() == part.lower():
                        value = value[key]
                        found = True
                        break
                if not found:
                    return None, False
        else:
            return None, False

    # Extract .value from parameter objects
    if isinstance(value, dict) and 'value' in value and 'html' not in value and 'latex' not in value:
        value = value['value']

    return value, True


def extract_pm_value_refs(html_content: str) -> List[Tuple[str, int]]:
    """Extract data-pm-value attribute values with line numbers."""
    refs = []
    pattern = r'data-pm-value=["\']([^"\']+)["\']'

    for i, line in enumerate(html_content.split('\n'), 1):
        for match in re.finditer(pattern, line):
            refs.append((match.group(1), i))

    return refs


def extract_pm_param_refs(html_content: str) -> List[Tuple[str, int]]:
    """Extract pm-param id attribute values with line numbers."""
    refs = []
    pattern = r'<pm-param[^>]+id=["\']([^"\']+)["\']'

    for i, line in enumerate(html_content.split('\n'), 1):
        for match in re.finditer(pattern, line):
            refs.append((match.group(1), i))

    return refs


def extract_category_param_refs(html_content: str) -> List[Tuple[str, str, int]]:
    """Extract data-category + data-param pairs with line numbers."""
    refs = []
    pattern = r'data-category=["\']([^"\']+)["\'][^>]*data-param=["\']([^"\']+)["\']'

    for i, line in enumerate(html_content.split('\n'), 1):
        for match in re.finditer(pattern, line):
            refs.append((match.group(1), match.group(2), i))

    return refs


def validate_html_file(html_path: Path, data: Dict[str, Any]) -> Dict[str, Any]:
    """Validate all parameter references in an HTML file."""
    with open(html_path, 'r', encoding='utf-8') as f:
        content = f.read()

    results = {
        'file': str(html_path.name),
        'pm_value': {'found': 0, 'missing': []},
        'pm_param': {'found': 0, 'missing': []},
        'category': {'found': 0, 'missing': []}
    }

    # Check data-pm-value refs
    for path, line_num in extract_pm_value_refs(content):
        value, found = get_value_by_path(data, path)
        if found and value is not None:
            results['pm_value']['found'] += 1
        else:
            results['pm_value']['missing'].append({
                'path': path,
                'line': line_num,
                'resolved': resolve_alias(path)
            })

    # Check pm-param refs
    for path, line_num in extract_pm_param_refs(content):
        value, found = get_value_by_path(data, path)
        if found and value is not None:
            results['pm_param']['found'] += 1
        else:
            results['pm_param']['missing'].append({
                'path': path,
                'line': line_num,
                'resolved': resolve_alias(path)
            })

    # Check data-category + data-param refs
    for category, param, line_num in extract_category_param_refs(content):
        # Try multiple path patterns
        paths_to_try = [
            f"simulations.{param}",
            f"simulations.{category}.{param}",
            f"parameters.{category}.{param}",
            f"{category}.{param}"
        ]

        found_any = False
        for try_path in paths_to_try:
            value, found = get_value_by_path(data, try_path)
            if found and value is not None:
                found_any = True
                break

        if found_any:
            results['category']['found'] += 1
        else:
            results['category']['missing'].append({
                'category': category,
                'param': param,
                'line': line_num,
                'tried_paths': paths_to_try
            })

    return results


def main():
    """Main validation routine."""
    base_dir = Path(__file__).parent.parent.parent

    print("=" * 60)
    print("Parameter Reference Validation")
    print("=" * 60)
    print(f"Base directory: {base_dir}")

    # Load theory_output.json
    try:
        data = load_theory_output(base_dir)
        print(f"Loaded theory_output.json (version: {data.get('version', 'unknown')})")
    except FileNotFoundError as e:
        print(f"ERROR: {e}")
        sys.exit(1)

    # Find all HTML files
    html_files = list(base_dir.glob('*.html'))
    html_files.extend(base_dir.glob('sections/*.html'))
    html_files.extend(base_dir.glob('docs/*.html'))

    print(f"\nScanning {len(html_files)} HTML files...")

    all_missing: Dict[str, Set[str]] = {
        'pm_value': set(),
        'pm_param': set(),
        'category': set()
    }

    total_found = 0
    total_missing = 0
    files_with_issues = []

    for html_file in sorted(html_files):
        results = validate_html_file(html_file, data)

        file_found = results['pm_value']['found'] + results['pm_param']['found'] + results['category']['found']
        file_missing = len(results['pm_value']['missing']) + len(results['pm_param']['missing']) + len(results['category']['missing'])

        total_found += file_found
        total_missing += file_missing

        # Collect unique missing paths
        for item in results['pm_value']['missing']:
            all_missing['pm_value'].add(item['path'])
        for item in results['pm_param']['missing']:
            all_missing['pm_param'].add(item['path'])
        for item in results['category']['missing']:
            all_missing['category'].add(f"{item['category']}.{item['param']}")

        if file_missing > 0:
            files_with_issues.append(results)

    # Print summary
    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print(f"Total references found: {total_found}")
    print(f"Total references missing: {total_missing}")

    if total_missing > 0:
        success_rate = (total_found / (total_found + total_missing)) * 100
        print(f"Success rate: {success_rate:.1f}%")
    else:
        print("Success rate: 100% - All references resolved!")

    # Print missing paths
    if total_missing > 0:
        print("\n" + "-" * 60)
        print("MISSING PARAMETER PATHS")
        print("-" * 60)

        if all_missing['pm_value']:
            print("\ndata-pm-value paths:")
            for path in sorted(all_missing['pm_value']):
                resolved = resolve_alias(path)
                if resolved != path:
                    print(f"  - {path}")
                    print(f"    -> resolves to: {resolved}")
                else:
                    print(f"  - {path}")

        if all_missing['pm_param']:
            print("\npm-param id paths:")
            for path in sorted(all_missing['pm_param']):
                resolved = resolve_alias(path)
                if resolved != path:
                    print(f"  - {path}")
                    print(f"    -> resolves to: {resolved}")
                else:
                    print(f"  - {path}")

        if all_missing['category']:
            print("\ndata-category.data-param paths:")
            for path in sorted(all_missing['category']):
                print(f"  - {path}")

        # Print files with issues
        print("\n" + "-" * 60)
        print("FILES WITH ISSUES")
        print("-" * 60)

        for result in files_with_issues:
            missing_count = len(result['pm_value']['missing']) + len(result['pm_param']['missing']) + len(result['category']['missing'])
            print(f"\n{result['file']} ({missing_count} missing):")

            for item in result['pm_value']['missing'][:5]:
                print(f"  Line {item['line']}: data-pm-value=\"{item['path']}\"")

            for item in result['pm_param']['missing'][:5]:
                print(f"  Line {item['line']}: pm-param id=\"{item['path']}\"")

            for item in result['category']['missing'][:5]:
                print(f"  Line {item['line']}: {item['category']}.{item['param']}")

            if missing_count > 5:
                print(f"  ... and {missing_count - 5} more")

    print("\n" + "=" * 60)

    # Exit with error code if issues found
    sys.exit(0 if total_missing == 0 else 1)


if __name__ == "__main__":
    main()
