#!/usr/bin/env python3
"""
PRINCIPIA METAPHYSICA - Repository Cleanup & Zenodo Packaging
==============================================================

This script creates a clean, OFFLINE Zenodo submission package by:
1. Cloning a fresh copy of the repository (or using local)
2. Removing all unnecessary files (temp scripts, deprecated sims, etc.)
3. STRIPPING Firebase/Auth dependencies for offline use
4. Organizing into academic submission structure
5. Generating SHA-256 manifest for verification
6. Creating validated ZIP archive

Usage:
    python tools/cleanup_and_package.py [--local] [--offline]

    --local     Use current repo instead of fresh clone (for testing)
    --offline   Strip Firebase/auth for standalone offline website

Copyright (c) 2025-2026 Andrew Keith Watts. All rights reserved.

Dedicated To:
    My Wife: Elizabeth May Watts
    Our Messiah: Jesus Of Nazareth
"""

import os
import sys
import re
import shutil
import zipfile
import json
import hashlib
import subprocess
import tempfile
import argparse
from pathlib import Path
from datetime import datetime
from typing import Set, List, Dict, Tuple, Optional

# ============================================================
# CONFIGURATION
# ============================================================

REPO_URL = "https://github.com/andrewkwatts-maker/PrincipiaMetaphysica.git"
REPO_BRANCH = "main"
VERSION = "16.2"
TITLE = f"Principia Metaphysica v{VERSION}"

SCRIPT_DIR = Path(__file__).parent
ROOT = SCRIPT_DIR.parent
OUTPUT_DIR = ROOT / "zenodo_submission"

# ============================================================
# FILES/PATTERNS TO REMOVE
# ============================================================

# Firebase/Auth files to DELETE for offline mode
FIREBASE_AUTH_FILES = [
    "*firebase*.js",
    "*firebase*.md",
    "*Firebase*.js",
    "*Firebase*.md",
    "auth-guard*.js",
    "auth-guard*.md",
    "secrets_config*",
    ".env*",
]

# Folders to always exclude
EXCLUDE_FOLDERS = [
    "__pycache__",
    ".git",
    ".github",
    ".claude",
    ".pytest_cache",
    "node_modules",
    "zenodo_submission",
    "zenodo_package",
]

# Deprecated simulation patterns
DEPRECATED_SIM_PATTERNS = [
    "*_v12_*.py",
    "*_v13_*.py",
    "*_v11_*.py",
    "*_v10_*.py",
]

# Temp file prefixes to remove
TEMP_PREFIXES = [
    "test-", "temp_", "batch", "verify_", "polish_",
    "update_", "migrate_", "add_", "check_", "detailed_",
]

# ============================================================
# ZENODO STRUCTURE
# ============================================================

ZENODO_STRUCTURE = {
    "01_Paper": {
        "description": "Complete interactive paper with formula rendering",
        "files": ["index.html", "validation.html"],
        "folders": ["css", "js", "fonts", "images", "components", "foundations", "Pages"],
    },
    "02_Simulations": {
        "description": "v16 simulation suite with 34 validated scripts",
        "files": ["config.py", "run_all_simulations.py", "requirements.txt"],
        "folders": ["simulations/v16", "simulations/base"],
    },
    "03_Data": {
        "description": "Generated theory output and parameter database",
        "files": [],
        "folders": ["AutoGenerated", "data"],
    },
    "04_Documentation": {
        "description": "Architecture, provenance, and usage documentation",
        "files": ["README.md", "ARCHITECTURE.md", "PROVENANCE.md", "CITATION.cff", "LICENSE"],
        "folders": ["docs", "diagrams"],
    },
    "05_Verification": {
        "description": "Wolfram certificates and formal proof manifests",
        "files": [],
        "folders": ["simulations/AutoGenerated"],
    },
    "06_Tests": {
        "description": "Validation and falsifiability test suite",
        "files": [],
        "folders": ["tests"],
    },
}

# ============================================================
# OFFLINE LOADER - Replaces Firebase
# ============================================================

OFFLINE_LOADER_JS = '''/**
 * PRINCIPIA METAPHYSICA - Offline Data Loader
 * ============================================
 * Replaces Firebase with local JSON file loading for offline use.
 * Copyright (c) 2025-2026 Andrew Keith Watts. All rights reserved.
 */

window.PM = window.PM || {};

PM.offlineData = {
    formulas: null,
    parameters: null,
    sections: null,
    theory: null,
    loaded: false
};

PM.getBasePath = function() {
    const path = window.location.pathname;
    if (path.includes('/01_Paper/')) return '../03_Data/AutoGenerated/';
    if (path.includes('/Pages/')) return '../AutoGenerated/';
    return './AutoGenerated/';
};

PM.loadJSON = async function(filename) {
    const basePath = PM.getBasePath();
    try {
        const response = await fetch(basePath + filename);
        if (!response.ok) throw new Error(`HTTP ${response.status}`);
        return await response.json();
    } catch (error) {
        console.warn(`[PM] Could not load ${filename}:`, error.message);
        return null;
    }
};

PM.initOffline = async function() {
    if (PM.offlineData.loaded) return;
    console.log('[PM] Loading offline data...');

    const [formulas, parameters, sections, theory] = await Promise.all([
        PM.loadJSON('formulas.json'),
        PM.loadJSON('parameters.json'),
        PM.loadJSON('sections.json'),
        PM.loadJSON('theory_output.json')
    ]);

    PM.offlineData.formulas = formulas;
    PM.offlineData.parameters = parameters;
    PM.offlineData.sections = sections;
    PM.offlineData.theory = theory;
    PM.offlineData.loaded = true;

    console.log('[PM] Offline data loaded');
    window.dispatchEvent(new CustomEvent('pm-data-ready'));
};

PM.getFormula = function(id) {
    if (!PM.offlineData.formulas) return null;
    const formulas = PM.offlineData.formulas.formulas || PM.offlineData.formulas;
    return formulas.find(f => f.id === id || f.formulaId === id);
};

PM.getParameter = function(path) {
    if (!PM.offlineData.parameters) return null;
    const params = PM.offlineData.parameters.parameters || PM.offlineData.parameters;
    return params.find(p => p.path === path || p.id === path || p.symbol === path);
};

PM.get = function(key) {
    const param = PM.getParameter(key);
    if (param) return { value: param.value || param.pmPredicted, units: param.units, name: param.name };
    return null;
};

if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', () => PM.initOffline());
} else {
    PM.initOffline();
}
'''

# ============================================================
# UTILITY FUNCTIONS
# ============================================================

def run_command(cmd: List[str], cwd: Optional[Path] = None) -> Tuple[int, str, str]:
    """Run shell command."""
    result = subprocess.run(cmd, cwd=cwd, capture_output=True, text=True)
    return result.returncode, result.stdout, result.stderr


def get_file_hash(filepath: Path) -> str:
    """Generate SHA-256 hash."""
    sha256 = hashlib.sha256()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha256.update(chunk)
    return sha256.hexdigest()


def format_size(size_bytes: int) -> str:
    """Format file size."""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    return f"{size_bytes / (1024 * 1024):.1f} MB"


# ============================================================
# CLONE & CLEAN FUNCTIONS
# ============================================================

def clone_fresh_repo(temp_dir: Path) -> Path:
    """Clone fresh repository."""
    print("\n" + "=" * 60)
    print("PHASE 1: Cloning Fresh Repository")
    print("=" * 60)

    clone_path = temp_dir / "PrincipiaMetaphysica"
    print(f"  Repository: {REPO_URL}")
    print(f"  Branch: {REPO_BRANCH}")

    cmd = ["git", "clone", "--depth", "1", "--branch", REPO_BRANCH, REPO_URL, str(clone_path)]
    returncode, stdout, stderr = run_command(cmd)

    if returncode != 0:
        raise RuntimeError(f"Git clone failed: {stderr}")

    print("  [OK] Cloned successfully")

    # Remove .git
    git_dir = clone_path / ".git"
    if git_dir.exists():
        shutil.rmtree(git_dir)
        print("  [OK] Removed .git folder")

    return clone_path


def clean_repo(repo_path: Path) -> Dict[str, int]:
    """Remove unnecessary files."""
    print("\n" + "=" * 60)
    print("PHASE 2: Cleaning Repository")
    print("=" * 60)

    stats = {"files": 0, "folders": 0, "bytes": 0}

    # Remove excluded folders
    for folder_name in EXCLUDE_FOLDERS:
        for folder in repo_path.rglob(folder_name):
            if folder.is_dir():
                size = sum(f.stat().st_size for f in folder.rglob("*") if f.is_file())
                stats["bytes"] += size
                shutil.rmtree(folder)
                stats["folders"] += 1
                print(f"  [DELETE] {folder.name}/")

    # Remove deprecated simulations
    sims_dir = repo_path / "simulations"
    if sims_dir.exists():
        for pattern in DEPRECATED_SIM_PATTERNS:
            for filepath in sims_dir.rglob(pattern):
                if "v16" not in str(filepath) and "base" not in str(filepath):
                    stats["bytes"] += filepath.stat().st_size
                    filepath.unlink()
                    stats["files"] += 1
                    print(f"  [DELETE] {filepath.name}")

    # Remove temp files from root
    for item in repo_path.iterdir():
        if item.is_file():
            if item.suffix in {".pyc", ".pyo", ".log", ".tmp", ".bak"}:
                stats["bytes"] += item.stat().st_size
                item.unlink()
                stats["files"] += 1
                continue

            if item.suffix == ".py" and any(item.name.startswith(p) for p in TEMP_PREFIXES):
                stats["bytes"] += item.stat().st_size
                item.unlink()
                stats["files"] += 1
                print(f"  [DELETE] {item.name}")

            if item.suffix == ".md" and any(x in item.name.upper() for x in ["BATCH", "SUMMARY", "REPORT", "STATUS"]):
                stats["bytes"] += item.stat().st_size
                item.unlink()
                stats["files"] += 1
                print(f"  [DELETE] {item.name}")

    print(f"\n  [OK] Removed {stats['files']} files, {stats['folders']} folders ({format_size(stats['bytes'])})")
    return stats


# ============================================================
# FIREBASE/AUTH STRIPPING (OFFLINE MODE)
# ============================================================

def strip_firebase_auth(package_path: Path) -> int:
    """Remove all Firebase/Auth files and references for offline use."""
    print("\n" + "=" * 60)
    print("PHASE 3: Stripping Firebase/Auth (Offline Mode)")
    print("=" * 60)

    deleted = 0

    # Delete Firebase/Auth files
    for pattern in FIREBASE_AUTH_FILES:
        for filepath in package_path.rglob(pattern):
            try:
                if filepath.is_file():
                    filepath.unlink()
                    deleted += 1
                    print(f"  [DELETE] {filepath.name}")
            except Exception as e:
                print(f"  [ERROR] {filepath}: {e}")

    # Create offline loader
    js_dir = package_path / "01_Paper" / "js"
    if js_dir.exists():
        loader_path = js_dir / "pm-offline-loader.js"
        with open(loader_path, 'w', encoding='utf-8') as f:
            f.write(OFFLINE_LOADER_JS)
        print(f"  [CREATE] pm-offline-loader.js")

    # Update HTML files to remove Firebase references and add offline loader
    html_updated = 0
    for html_file in package_path.rglob("*.html"):
        try:
            content = html_file.read_text(encoding='utf-8')
            original = content

            # Remove Firebase script tags
            content = re.sub(
                r'<script[^>]*firebase[^>]*>.*?</script>',
                '', content, flags=re.IGNORECASE | re.DOTALL
            )
            content = re.sub(
                r'<script[^>]*auth-guard[^>]*>.*?</script>',
                '', content, flags=re.IGNORECASE | re.DOTALL
            )

            # Add offline loader if not present
            if 'pm-offline-loader.js' not in content:
                head_close = content.find('</head>')
                if head_close > 0:
                    inject = '\n    <script src="js/pm-offline-loader.js"></script>\n'
                    content = content[:head_close] + inject + content[head_close:]

            if content != original:
                html_file.write_text(content, encoding='utf-8')
                html_updated += 1

        except Exception as e:
            print(f"  [ERROR] {html_file}: {e}")

    print(f"\n  [OK] Deleted {deleted} Firebase/auth files")
    print(f"  [OK] Updated {html_updated} HTML files for offline use")
    return deleted


# ============================================================
# PACKAGE CREATION
# ============================================================

def create_package_structure(source_path: Path, output_path: Path) -> List[Dict]:
    """Create organized Zenodo package structure."""
    print("\n" + "=" * 60)
    print("PHASE 4: Creating Package Structure")
    print("=" * 60)

    if output_path.exists():
        shutil.rmtree(output_path)
    output_path.mkdir(parents=True)

    file_manifest = []

    for section_name, section_config in ZENODO_STRUCTURE.items():
        section_dir = output_path / section_name
        section_dir.mkdir(parents=True, exist_ok=True)
        print(f"\n  Creating {section_name}/")

        # Copy files
        for filename in section_config.get("files", []):
            source = source_path / filename
            if source.exists():
                dest = section_dir / source.name
                shutil.copy2(source, dest)
                file_manifest.append({
                    "path": f"{section_name}/{source.name}",
                    "size": dest.stat().st_size,
                    "sha256": get_file_hash(dest)
                })
                print(f"    [COPY] {filename}")

        # Copy folders
        for folder_path in section_config.get("folders", []):
            source = source_path / folder_path
            if source.exists():
                folder_name = Path(folder_path).name
                dest = section_dir / folder_name
                shutil.copytree(
                    source, dest,
                    ignore=shutil.ignore_patterns('__pycache__', '*.pyc', '.git', '.DS_Store')
                )
                print(f"    [COPY DIR] {folder_path}/")
                for f in dest.rglob("*"):
                    if f.is_file():
                        file_manifest.append({
                            "path": str(f.relative_to(output_path)),
                            "size": f.stat().st_size,
                            "sha256": get_file_hash(f)
                        })

    return file_manifest


def create_manifest(output_path: Path, file_manifest: List[Dict]) -> Dict:
    """Create package manifest."""
    print("\n" + "=" * 60)
    print("PHASE 5: Creating Manifest")
    print("=" * 60)

    total_size = sum(f["size"] for f in file_manifest)
    section_counts = {}
    for f in file_manifest:
        section = f["path"].split("/")[0] if "/" in f["path"] else "root"
        section_counts[section] = section_counts.get(section, 0) + 1

    manifest = {
        "title": TITLE,
        "version": VERSION,
        "author": "Andrew Keith Watts",
        "affiliation": "Independent Physics Researcher - Brisbane, Australia",
        "repository": "https://github.com/andrewkwatts-maker/PrincipiaMetaphysica",
        "created": datetime.now().isoformat(),
        "description": "A unified geometric framework deriving all 58 Standard Model parameters from a single G2 manifold.",
        "keywords": ["theoretical physics", "G2 manifold", "Standard Model", "gauge unification"],
        "statistics": {
            "total_files": len(file_manifest),
            "total_size_bytes": total_size,
            "total_size_human": format_size(total_size),
            "files_by_section": section_counts,
        },
        "files": file_manifest
    }

    manifest_path = output_path / "MANIFEST.json"
    with open(manifest_path, 'w') as f:
        json.dump(manifest, f, indent=2)

    print(f"  Total files: {len(file_manifest)}")
    print(f"  Total size: {format_size(total_size)}")
    print("  [CREATE] MANIFEST.json")
    return manifest


def create_readme(output_path: Path) -> None:
    """Create Zenodo README."""
    readme = f"""# {TITLE} - Zenodo Submission

## A First-Principles Geometric Theory

A unified geometric framework deriving all 58 Standard Model parameters
from a single G2 manifold with minimal calibration (1 fitted parameter: alpha_GUT).

### Author
Andrew Keith Watts - Independent Physics Researcher, Brisbane, Australia

### Package Contents
| Folder | Description |
|--------|-------------|
| 01_Paper/ | Interactive paper (works offline) |
| 02_Simulations/ | v16 simulation suite (34 scripts) |
| 03_Data/ | Theory output and parameters |
| 04_Documentation/ | Architecture and provenance |
| 05_Verification/ | Wolfram certificates |
| 06_Tests/ | Validation test suite |

### Quick Start
1. Open `01_Paper/index.html` in browser
2. Run simulations: `cd 02_Simulations && python run_all_simulations.py`

### Key Results
- 58 parameters derived from G2 geometry
- 34/34 simulations pass (100%)
- 35 formal proofs with Wolfram certificates
- 87.2% agreement with experimental data

### License
Copyright (c) 2025-2026 Andrew Keith Watts. All rights reserved.

---
*Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    with open(output_path / "README.md", 'w') as f:
        f.write(readme)
    print("  [CREATE] README.md")


def create_zip(output_path: Path, dest_path: Path) -> Path:
    """Create ZIP archive."""
    print("\n" + "=" * 60)
    print("PHASE 6: Creating ZIP Archive")
    print("=" * 60)

    zip_name = f"Principia_Metaphysica_v{VERSION}_{datetime.now().strftime('%Y%m%d')}.zip"
    zip_path = dest_path / zip_name

    if zip_path.exists():
        zip_path.unlink()

    count = 0
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=9) as zipf:
        for root_dir, dirs, files in os.walk(output_path):
            dirs[:] = [d for d in dirs if d != '__pycache__']
            for file in files:
                file_path = Path(root_dir) / file
                arc_name = file_path.relative_to(output_path)
                zipf.write(file_path, arc_name)
                count += 1

    print(f"  Files: {count}")
    print(f"  Size: {format_size(zip_path.stat().st_size)}")
    print(f"  [OK] Created {zip_name}")
    return zip_path


def validate_package(output_path: Path) -> Tuple[bool, List[str]]:
    """Validate package."""
    print("\n" + "=" * 60)
    print("PHASE 7: Validating Package")
    print("=" * 60)

    issues = []

    # Check sections exist
    for section in ZENODO_STRUCTURE.keys():
        section_path = output_path / section
        if not section_path.exists() or not any(section_path.iterdir()):
            issues.append(f"Missing/empty section: {section}")

    # Check no Firebase files
    for pattern in ["*firebase*", "*Firebase*", "auth-guard*"]:
        if list(output_path.rglob(pattern)):
            issues.append(f"Firebase/auth files still present")
            break

    # Check critical files
    critical = [
        "01_Paper/index.html",
        "02_Simulations/config.py",
        "03_Data/AutoGenerated/theory_output.json",
        "MANIFEST.json",
    ]
    for f in critical:
        if not (output_path / f).exists():
            issues.append(f"Missing: {f}")

    if issues:
        print("  ISSUES:")
        for issue in issues:
            print(f"    [!] {issue}")
        return False, issues

    print("  [OK] All checks passed")
    return True, []


# ============================================================
# MAIN
# ============================================================

def main():
    parser = argparse.ArgumentParser(description="Create Zenodo package")
    parser.add_argument("--local", action="store_true", help="Use local repo")
    parser.add_argument("--offline", action="store_true", default=True, help="Strip Firebase for offline (default: True)")
    parser.add_argument("--output", type=str, default=None, help="Output directory")
    args = parser.parse_args()

    print("=" * 60)
    print("PRINCIPIA METAPHYSICA - Zenodo Package Creator")
    print("=" * 60)
    print(f"Version: {VERSION}")
    print(f"Offline Mode: {args.offline}")

    output_path = Path(args.output) if args.output else OUTPUT_DIR
    temp_dir = None

    if args.local:
        print(f"\nMode: LOCAL")
        source_path = ROOT
    else:
        print(f"\nMode: FRESH CLONE")
        temp_dir = Path(tempfile.mkdtemp(prefix="pm_zenodo_"))
        try:
            source_path = clone_fresh_repo(temp_dir)
            clean_repo(source_path)
        except Exception as e:
            print(f"[ERROR] {e}")
            if temp_dir and temp_dir.exists():
                shutil.rmtree(temp_dir)
            sys.exit(1)

    try:
        # Create package
        file_manifest = create_package_structure(source_path, output_path)

        # Strip Firebase if offline mode
        if args.offline:
            strip_firebase_auth(output_path)

        # Create manifest and readme
        create_manifest(output_path, file_manifest)
        create_readme(output_path)

        # Create ZIP
        zip_path = create_zip(output_path, ROOT)

        # Validate
        valid, issues = validate_package(output_path)

        print("\n" + "=" * 60)
        print("SUMMARY")
        print("=" * 60)
        print(f"  Package: {output_path}")
        print(f"  ZIP: {zip_path}")
        print(f"  Status: {'READY' if valid else 'NEEDS REVIEW'}")

    finally:
        if temp_dir and temp_dir.exists():
            shutil.rmtree(temp_dir)


if __name__ == "__main__":
    main()
